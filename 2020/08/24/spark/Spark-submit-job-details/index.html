<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jtlibrain.github.io","root":"/","scheme":"Gemini","version":"8.0.0-rc.5","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false};
  </script>

  <meta name="description" content="本篇介绍Spark是如何将我们定义的代码以作业的形式提交至集群的。本篇主要关注于作业提交，作业提交后任务的运行在《Spark运行任务原理》中有详细讲述。">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark提交作业原理">
<meta property="og:url" content="https://jtlibrain.github.io/2020/08/24/spark/Spark-submit-job-details/index.html">
<meta property="og:site_name" content="jtLiBrain">
<meta property="og:description" content="本篇介绍Spark是如何将我们定义的代码以作业的形式提交至集群的。本篇主要关注于作业提交，作业提交后任务的运行在《Spark运行任务原理》中有详细讲述。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/submit-job.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/DAGScheduler-getShuffleDependencies-case.svg">
<meta property="article:published_time" content="2020-08-24T02:56:34.000Z">
<meta property="article:modified_time" content="2020-09-24T06:49:17.108Z">
<meta property="article:author" content="JT Li">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jtlibrain.github.io/images/spark/submit-job.svg">

<link rel="canonical" href="https://jtlibrain.github.io/2020/08/24/spark/Spark-submit-job-details/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Spark提交作业原理 | jtLiBrain</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">jtLiBrain</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">任何伟大的事都不会一蹴而就，三分智慧，七分韧性</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#LiveListenerBus"><span class="nav-number">1.</span> <span class="nav-text">LiveListenerBus</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#OutputCommitCoordinator"><span class="nav-number">2.</span> <span class="nav-text">OutputCommitCoordinator</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MapOutputTrackerMaster"><span class="nav-number">3.</span> <span class="nav-text">MapOutputTrackerMaster</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ShuffleMapStage"><span class="nav-number">4.</span> <span class="nav-text">ShuffleMapStage</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#DAGScheduler"><span class="nav-number">5.</span> <span class="nav-text">DAGScheduler</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#DAGSchedulerEventProcessLoop"><span class="nav-number">5.1.</span> <span class="nav-text">DAGSchedulerEventProcessLoop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E4%BA%A4%E4%BD%9C%E4%B8%9A"><span class="nav-number">5.2.</span> <span class="nav-text">提交作业</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%84%E5%BB%BAStage%E5%9B%BE"><span class="nav-number">5.3.</span> <span class="nav-text">构建Stage图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E4%BA%A4Stage"><span class="nav-number">5.4.</span> <span class="nav-text">提交Stage</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1"><span class="nav-number">5.5.</span> <span class="nav-text">提交任务</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TaskSchedulerImpl"><span class="nav-number">6.</span> <span class="nav-text">TaskSchedulerImpl</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1-1"><span class="nav-number">6.1.</span> <span class="nav-text">提交任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E9%85%8D%E4%BB%BB%E5%8A%A1"><span class="nav-number">6.2.</span> <span class="nav-text">分配任务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%BD%E8%B8%AA%E4%BB%BB%E5%8A%A1%E7%8A%B6%E6%80%81"><span class="nav-number">6.3.</span> <span class="nav-text">追踪任务状态</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TaskSetManager"><span class="nav-number">6.4.</span> <span class="nav-text">TaskSetManager</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CoarseGrainedSchedulerBackend"><span class="nav-number">7.</span> <span class="nav-text">CoarseGrainedSchedulerBackend</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#DriverEndpoint"><span class="nav-number">7.1.</span> <span class="nav-text">DriverEndpoint</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CoarseGrainedExecutorBackend"><span class="nav-number">8.</span> <span class="nav-text">CoarseGrainedExecutorBackend</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TODO"><span class="nav-number">9.</span> <span class="nav-text">TODO</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NOTEs"><span class="nav-number">10.</span> <span class="nav-text">NOTEs</span></a></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">JT Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:jtli.brain@hotmail.com" title="E-Mail → mailto:jtli.brain@hotmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </section>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


      <div class="main-inner">
        

        <div class="content post posts-expand">
          

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jtlibrain.github.io/2020/08/24/spark/Spark-submit-job-details/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JT Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jtLiBrain">
    </span>

    
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark提交作业原理
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-24 10:56:34" itemprop="dateCreated datePublished" datetime="2020-08-24T10:56:34+08:00">2020-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-09-24 14:49:17" itemprop="dateModified" datetime="2020-09-24T14:49:17+08:00">2020-09-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/spark/" itemprop="url" rel="index"><span itemprop="name">spark</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>本篇介绍Spark是如何将我们定义的代码以作业的形式提交至集群的。本篇主要关注于作业提交，作业提交后任务的运行在《<a href="/2020/08/28/Spark-run-task-details">Spark运行任务原理</a>》中有详细讲述。</p>
<a id="more"></a>

<p><img src="/images/spark/submit-job.svg"></p>
<h1 id="LiveListenerBus"><a href="#LiveListenerBus" class="headerlink" title="LiveListenerBus"></a>LiveListenerBus</h1><h1 id="OutputCommitCoordinator"><a href="#OutputCommitCoordinator" class="headerlink" title="OutputCommitCoordinator"></a>OutputCommitCoordinator</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// key为stageId，value是StageState</span></span><br><span class="line"><span class="comment">// StageState表示的是</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> stageStates = mutable.<span class="type">Map</span>[<span class="type">Int</span>, <span class="type">StageState</span>]()</span><br></pre></td></tr></table></figure>



<h1 id="MapOutputTrackerMaster"><a href="#MapOutputTrackerMaster" class="headerlink" title="MapOutputTrackerMaster"></a>MapOutputTrackerMaster</h1><p>此类用于追踪stage的map输出位置。DAGScheduler使用此类来注册/注销map输出状态，以及为执行位置感知的reduce任务而查找统计信息。内部，MapOutputTrackerMaster使用ShuffleStatus对shuffle状态进行记录。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 登记的Shuffle状态，key为shuffleId，value是一个ShuffleStatus类型</span></span><br><span class="line"><span class="keyword">val</span> shuffleStatuses = <span class="keyword">new</span> <span class="type">ConcurrentHashMap</span>[<span class="type">Int</span>, <span class="type">ShuffleStatus</span>]().asScala</span><br></pre></td></tr></table></figure>



<h1 id="ShuffleMapStage"><a href="#ShuffleMapStage" class="headerlink" title="ShuffleMapStage"></a>ShuffleMapStage</h1><p>在DAG执行当中，ShuffleMapStage是作为一种中间状态的stage，它用来为shuffle产生数据。<code>shuffleDep</code>表示的是该stage是作为某个shuffle的一部分，更确切地说，当前ShuffleMapStage为<code>shuffleDep</code>所表示的shuffle输出map端中间数据。所以我们可以理解为shuffle依赖是一个stage的创建依据：即，为shuffle依赖上游创建一个stage，这个stage末尾会运行map任务为此shuffle操作产生中间数据。</p>
<h1 id="DAGScheduler"><a href="#DAGScheduler" class="headerlink" title="DAGScheduler"></a>DAGScheduler</h1><p>DAGScheduler是高层级的调度层，它是面向stage的调度。它负责为任务计算stage DAG、追踪哪些RDD和哪些stage的输出是已经被物化了的、并且寻找最佳的调度策略来运行任务。之后，它会将stages以TaskSet的形式提交到底层TaskScheduler。</p>
<p>除此，它还担负了在由于shuffle输出文件丢失导致失败时，重提交上游stages的任务；以及在作业执行完成后，对作业所涉及的数据结构的清理。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 包含被缓存的RDD分区的位置，其中Map中的：</span></span><br><span class="line"><span class="comment"> * key为RDD的ID；value表示的数组的索引为分区编号，数组项表示该分区被缓存的位置集合。</span></span><br><span class="line"><span class="comment"> * 每次job执行完都会进行清理缓存的数据。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> cacheLocs = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">IndexedSeq</span>[<span class="type">Seq</span>[<span class="type">TaskLocation</span>]]]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等待运行的Stage，它们的上游stage还没有完成</span></span><br><span class="line"><span class="keyword">private</span>[scheduler] <span class="keyword">val</span> waitingStages = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当前在运行的stage</span></span><br><span class="line"><span class="keyword">private</span>[scheduler] <span class="keyword">val</span> runningStages = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[scheduler] <span class="keyword">val</span> activeJobs = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">ActiveJob</span>]</span><br></pre></td></tr></table></figure>

<h2 id="DAGSchedulerEventProcessLoop"><a href="#DAGSchedulerEventProcessLoop" class="headerlink" title="DAGSchedulerEventProcessLoop"></a>DAGSchedulerEventProcessLoop</h2><p>它继承自<code>EventLoop[DAGSchedulerEvent]</code>，作为接收DAGSchedulerEvent事件类型的环路。</p>
<p>在内部，使用阻塞队列作为消息队列，接收调用者发送的消息；运行一个专门的线程来处理所有事件，并将接收到的消息根据消息类型，交由DAGScheduler进一步处理。</p>
<h2 id="提交作业"><a href="#提交作业" class="headerlink" title="提交作业"></a>提交作业</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">  <span class="comment">// Check to make sure we are not launching a task on a partition that does not exist.</span></span><br><span class="line">  <span class="keyword">val</span> maxPartitions = rdd.partitions.length</span><br><span class="line">  partitions.find(p =&gt; p &gt;= maxPartitions || p &lt; <span class="number">0</span>).foreach &#123; p =&gt;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</span><br><span class="line">      <span class="string">&quot;Attempting to access a non-existent partition: &quot;</span> + p + <span class="string">&quot;. &quot;</span> +</span><br><span class="line">        <span class="string">&quot;Total number of partitions: &quot;</span> + maxPartitions)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> jobId = nextJobId.getAndIncrement() <span class="comment">// 分配作业ID</span></span><br><span class="line">  <span class="keyword">if</span> (partitions.size == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Return immediately if the job is running 0 tasks</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, <span class="number">0</span>, resultHandler)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  assert(partitions.size &gt; <span class="number">0</span>)</span><br><span class="line">  <span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</span><br><span class="line">  <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</span><br><span class="line">  <span class="comment">// 发送JobSubmitted消息到eventProcessLoop</span></span><br><span class="line">  eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">    jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">    <span class="type">SerializationUtils</span>.clone(properties)))</span><br><span class="line">  waiter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</span><br><span class="line">  <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</span><br><span class="line">  <span class="type">ThreadUtils</span>.awaitReady(waiter.completionFuture, <span class="type">Duration</span>.<span class="type">Inf</span>)</span><br><span class="line">  waiter.completionFuture.value.get <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Success</span>(_) =&gt;</span><br><span class="line">      logInfo(<span class="string">&quot;Job %d finished: %s, took %f s&quot;</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">    <span class="keyword">case</span> scala.util.<span class="type">Failure</span>(exception) =&gt;</span><br><span class="line">      logInfo(<span class="string">&quot;Job %d failed: %s, took %f s&quot;</span>.format</span><br><span class="line">        (waiter.jobId, callSite.shortForm, (<span class="type">System</span>.nanoTime - start) / <span class="number">1e9</span>))</span><br><span class="line">      <span class="comment">// SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.</span></span><br><span class="line">      <span class="keyword">val</span> callerStackTrace = <span class="type">Thread</span>.currentThread().getStackTrace.tail</span><br><span class="line">      exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)</span><br><span class="line">      <span class="keyword">throw</span> exception</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</span><br><span class="line">    finalRDD: <span class="type">RDD</span>[_],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">    partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    listener: <span class="type">JobListener</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 构建stage的DAG</span></span><br><span class="line">    finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    ... ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Job submitted, clear internal data.</span></span><br><span class="line">  barrierJobIdToNumTasksCheckFailures.remove(jobId)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</span><br><span class="line">  clearCacheLocs()</span><br><span class="line">  logInfo(<span class="string">&quot;Got job %s (%s) with %d output partitions&quot;</span>.format(</span><br><span class="line">    job.jobId, callSite.shortForm, partitions.length))</span><br><span class="line">  logInfo(<span class="string">&quot;Final stage: &quot;</span> + finalStage + <span class="string">&quot; (&quot;</span> + finalStage.name + <span class="string">&quot;)&quot;</span>)</span><br><span class="line">  logInfo(<span class="string">&quot;Parents of final stage: &quot;</span> + finalStage.parents)</span><br><span class="line">  logInfo(<span class="string">&quot;Missing parents: &quot;</span> + getMissingParentStages(finalStage))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> jobSubmissionTime = clock.getTimeMillis()</span><br><span class="line">  jobIdToActiveJob(jobId) = job</span><br><span class="line">  activeJobs += job</span><br><span class="line">  finalStage.setActiveJob(job)</span><br><span class="line">  <span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</span><br><span class="line">  <span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</span><br><span class="line">  listenerBus.post(</span><br><span class="line">    <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos, properties))</span><br><span class="line">  submitStage(finalStage)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="构建Stage图"><a href="#构建Stage图" class="headerlink" title="构建Stage图"></a>构建Stage图</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建为计算RDD所需要的ResultStage</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createResultStage</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">    partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    jobId: <span class="type">Int</span>,</span><br><span class="line">    callSite: <span class="type">CallSite</span>): <span class="type">ResultStage</span> = &#123;</span><br><span class="line">  checkBarrierStageWithDynamicAllocation(rdd)</span><br><span class="line">  checkBarrierStageWithNumSlots(rdd)</span><br><span class="line">  checkBarrierStageWithRDDChainPattern(rdd, partitions.toSet.size)</span><br><span class="line">  <span class="comment">// 首先，计算当前rdd的上游stage列表</span></span><br><span class="line">  <span class="keyword">val</span> parents = getOrCreateParentStages(rdd, jobId)</span><br><span class="line">  <span class="keyword">val</span> id = nextStageId.getAndIncrement()</span><br><span class="line">  <span class="comment">// 以当前rdd为基础创建ResultStage</span></span><br><span class="line">  <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parents, jobId, callSite)</span><br><span class="line">  stageIdToStage(id) = stage</span><br><span class="line">  updateJobIdStageIdMaps(jobId, stage)</span><br><span class="line">  stage</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 获取/构建给定RDD的上游Stage列表，也就是说当前的rdd不在所返回的上游父亲Stage列表中，</span></span><br><span class="line"><span class="comment"> * 其中，构建的依据是依赖图中离当前rdd最近shuffle依赖；</span></span><br><span class="line"><span class="comment"> * 并且，Stage是一个树状结构，在这个方法返回时，Stage列表中的每个Stage树也已经构建完成。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getOrCreateParentStages</span></span>(rdd: <span class="type">RDD</span>[_], firstJobId: <span class="type">Int</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</span><br><span class="line">  getShuffleDependencies(rdd).map &#123; shuffleDep =&gt;</span><br><span class="line">    <span class="comment">// 以shuffle依赖为依据创建相应的ShuffleMapStage</span></span><br><span class="line">    getOrCreateShuffleMapStage(shuffleDep, firstJobId)</span><br><span class="line">  &#125;.toList</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用了“栈+loop”编程范式来遍历rdd的依赖树，返回离给定RDD最近的shuffle依赖。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">getShuffleDependencies</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_]): <span class="type">HashSet</span>[<span class="type">ShuffleDependency</span>[_, _, _]] = &#123;</span><br><span class="line">  <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">ShuffleDependency</span>[_, _, _]]</span><br><span class="line">  <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">ArrayStack</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  waitingForVisit.push(rdd)</span><br><span class="line">  <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">val</span> toVisit = waitingForVisit.pop()</span><br><span class="line">    <span class="keyword">if</span> (!visited(toVisit)) &#123;</span><br><span class="line">      visited += toVisit</span><br><span class="line">      toVisit.dependencies.foreach &#123;</span><br><span class="line">        <span class="keyword">case</span> shuffleDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</span><br><span class="line">          parents += shuffleDep <span class="comment">// 如果是ShuffleDependency，则加入返回列表中，当前分支不再深度遍历</span></span><br><span class="line">        <span class="keyword">case</span> dependency =&gt;</span><br><span class="line">          waitingForVisit.push(dependency.rdd) <span class="comment">// 否则，深度继续向下一层遍历</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  parents</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查找给定rdd上游所有还未注册过的shuffle依赖，并以堆栈的形式返回，最近shuffle依赖在栈底，</span></span><br><span class="line"><span class="comment"> * 最远shuffle依赖在栈顶。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getMissingAncestorShuffleDependencies</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_]): <span class="type">ArrayStack</span>[<span class="type">ShuffleDependency</span>[_, _, _]] = &#123;</span><br><span class="line">  <span class="keyword">val</span> ancestors = <span class="keyword">new</span> <span class="type">ArrayStack</span>[<span class="type">ShuffleDependency</span>[_, _, _]]</span><br><span class="line">  <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></span><br><span class="line">  <span class="comment">// caused by recursively visiting</span></span><br><span class="line">  <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">ArrayStack</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  waitingForVisit.push(rdd)</span><br><span class="line">  <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">val</span> toVisit = waitingForVisit.pop()</span><br><span class="line">    <span class="keyword">if</span> (!visited(toVisit)) &#123;</span><br><span class="line">      visited += toVisit</span><br><span class="line">      getShuffleDependencies(toVisit).foreach &#123; shuffleDep =&gt;</span><br><span class="line">        <span class="keyword">if</span> (!shuffleIdToMapStage.contains(shuffleDep.shuffleId)) &#123;</span><br><span class="line">          ancestors.push(shuffleDep)</span><br><span class="line">          waitingForVisit.push(shuffleDep.rdd) <span class="comment">//继续深度遍历祖先</span></span><br><span class="line">        &#125; <span class="comment">// Otherwise, the dependency and its ancestors have already been registered.</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ancestors</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>举例来说，如图所示，5个RDD，其中箭头代表依赖关系。那么，C的最近shuffle依赖是到B依赖；D的最近shuffle依赖是到C的依赖，E的最近shuffle依赖是到A和到C的依赖。</p>
<p><img src="/images/spark/DAGScheduler-getShuffleDependencies-case.svg"></p>
<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 获取或创建给定shuffle依赖所对应的ShuffleMapStage。</span></span><br><span class="line"><span class="comment"> * 如果ShuffleIdToMapStage已经存在于shuffleIdToMapStage，直接返回；</span></span><br><span class="line"><span class="comment"> * 否则，该方法会创建相应的ShuffleMapStage，并同时会解决其所有缺失的祖先ShuffleMapStage。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getOrCreateShuffleMapStage</span></span>(</span><br><span class="line">    shuffleDep: <span class="type">ShuffleDependency</span>[_, _, _],</span><br><span class="line">    firstJobId: <span class="type">Int</span>): <span class="type">ShuffleMapStage</span> = &#123;</span><br><span class="line">  shuffleIdToMapStage.get(shuffleDep.shuffleId) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(stage) =&gt;</span><br><span class="line">      stage</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">      <span class="comment">// 首先，创建所有上游stages</span></span><br><span class="line">      <span class="comment">// 注意，这里getMissingAncestorShuffleDependencies()返回的是栈，所以会先创建最前面的stage</span></span><br><span class="line">      getMissingAncestorShuffleDependencies(shuffleDep.rdd).foreach &#123; dep =&gt;</span><br><span class="line">        <span class="comment">// Even though getMissingAncestorShuffleDependencies only returns shuffle dependencies</span></span><br><span class="line">        <span class="comment">// that were not already in shuffleIdToMapStage, it&#x27;s possible that by the time we</span></span><br><span class="line">        <span class="comment">// get to a particular dependency in the foreach loop, it&#x27;s been added to</span></span><br><span class="line">        <span class="comment">// shuffleIdToMapStage by the stage creation process for an earlier dependency. See</span></span><br><span class="line">        <span class="comment">// SPARK-13902 for more information.</span></span><br><span class="line">        <span class="keyword">if</span> (!shuffleIdToMapStage.contains(dep.shuffleId)) &#123;</span><br><span class="line">          createShuffleMapStage(dep, firstJobId)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 然后，创建当前stage</span></span><br><span class="line">      createShuffleMapStage(shuffleDep, firstJobId)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建shuffle依赖所在的stage</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createShuffleMapStage</span></span>(shuffleDep: <span class="type">ShuffleDependency</span>[_, _, _], jobId: <span class="type">Int</span>): <span class="type">ShuffleMapStage</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> rdd = shuffleDep.rdd <span class="comment">// shuffle依赖的RDD作为ShuffleMapStage的rdd，也即map任务运行所作用的rdd</span></span><br><span class="line">  checkBarrierStageWithDynamicAllocation(rdd)</span><br><span class="line">  checkBarrierStageWithNumSlots(rdd)</span><br><span class="line">  checkBarrierStageWithRDDChainPattern(rdd, rdd.getNumPartitions)</span><br><span class="line">  <span class="keyword">val</span> numTasks = rdd.partitions.length <span class="comment">// 每个stage的并行度水平是与stage中最后一个rdd并行度一致的</span></span><br><span class="line">  <span class="keyword">val</span> parents = getOrCreateParentStages(rdd, jobId) <span class="comment">// 递归地构建当前stage所依赖的父stage列表</span></span><br><span class="line">  <span class="keyword">val</span> id = nextStageId.getAndIncrement()</span><br><span class="line">  <span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ShuffleMapStage</span>(</span><br><span class="line">    id, rdd, numTasks, parents, jobId, rdd.creationSite, shuffleDep, mapOutputTracker)</span><br><span class="line"></span><br><span class="line">  stageIdToStage(id) = stage</span><br><span class="line">  shuffleIdToMapStage(shuffleDep.shuffleId) = stage</span><br><span class="line">  updateJobIdStageIdMaps(jobId, stage)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!mapOutputTracker.containsShuffle(shuffleDep.shuffleId)) &#123;</span><br><span class="line">    <span class="comment">// Kind of ugly: need to register RDDs with the cache and map output tracker here</span></span><br><span class="line">    <span class="comment">// since we can&#x27;t do it in the RDD constructor because # of partitions is unknown</span></span><br><span class="line">    logInfo(<span class="string">&quot;Registering RDD &quot;</span> + rdd.id + <span class="string">&quot; (&quot;</span> + rdd.getCreationSite + <span class="string">&quot;)&quot;</span>)</span><br><span class="line">    mapOutputTracker.registerShuffle(shuffleDep.shuffleId, rdd.partitions.length)</span><br><span class="line">  &#125;</span><br><span class="line">  stage</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="提交Stage"><a href="#提交Stage" class="headerlink" title="提交Stage"></a>提交Stage</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 提交stage，在提交当前stage前，首先递归地提交其祖先stage</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>) &#123;</span><br><span class="line">  <span class="comment">// 查找需要此stage的最早被创建的活跃作业</span></span><br><span class="line">  <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">    logDebug(<span class="string">&quot;submitStage(&quot;</span> + stage + <span class="string">&quot;)&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">      <span class="comment">// 查找当前stage最近祖先stage当中的不可用stage</span></span><br><span class="line">      <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">      logDebug(<span class="string">&quot;missing: &quot;</span> + missing)</span><br><span class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123; <span class="comment">// 如果当前stage上游stage全部可用，那么提交当前stage</span></span><br><span class="line">        logInfo(<span class="string">&quot;Submitting &quot;</span> + stage + <span class="string">&quot; (&quot;</span> + stage.rdd + <span class="string">&quot;), which has no missing parents&quot;</span>)</span><br><span class="line">        submitMissingTasks(stage, jobId.get)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则，递归地提交不可用的最近祖先stage</span></span><br><span class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">          submitStage(parent)</span><br><span class="line">        &#125;</span><br><span class="line">        waitingStages += stage <span class="comment">// 当前stage标记为等待状态</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    abortStage(stage, <span class="string">&quot;No active job for stage &quot;</span> + stage.id, <span class="type">None</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查找当前stage的最近上游祖先stage，如果不可用将其返回</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getMissingParentStages</span></span>(stage: <span class="type">Stage</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> missing = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</span><br><span class="line">  <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></span><br><span class="line">  <span class="comment">// caused by recursively visiting</span></span><br><span class="line">  <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">ArrayStack</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(rdd: <span class="type">RDD</span>[_]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!visited(rdd)) &#123;</span><br><span class="line">      visited += rdd</span><br><span class="line">      <span class="comment">// 查找该rdd是否被缓存过</span></span><br><span class="line">      <span class="keyword">val</span> rddHasUncachedPartitions = getCacheLocs(rdd).contains(<span class="type">Nil</span>)</span><br><span class="line">      <span class="keyword">if</span> (rddHasUncachedPartitions) &#123;</span><br><span class="line">        <span class="keyword">for</span> (dep &lt;- rdd.dependencies) &#123;</span><br><span class="line">          dep <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</span><br><span class="line">              <span class="keyword">val</span> mapStage = getOrCreateShuffleMapStage(shufDep, stage.firstJobId)</span><br><span class="line">              <span class="keyword">if</span> (!mapStage.isAvailable) &#123; <span class="comment">// 如果stage不可用，作为返回结果返回</span></span><br><span class="line">                missing += mapStage</span><br><span class="line">              &#125;</span><br><span class="line">            <span class="keyword">case</span> narrowDep: <span class="type">NarrowDependency</span>[_] =&gt; <span class="comment">// 窄依赖继续深度遍历</span></span><br><span class="line">              waitingForVisit.push(narrowDep.rdd)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  waitingForVisit.push(stage.rdd)</span><br><span class="line">  <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</span><br><span class="line">    visit(waitingForVisit.pop())</span><br><span class="line">  &#125;</span><br><span class="line">  missing.toList</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h2><p>我们来分析一下submitMissingTasks方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Called when stage&#x27;s parents are available and we can now do its task. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>) &#123;</span><br><span class="line">  logDebug(<span class="string">&quot;submitMissingTasks(&quot;</span> + stage + <span class="string">&quot;)&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 1. 计算当前stage待计算的分区IDs</span></span><br><span class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Use the scheduling pool, job group, description, etc. from an ActiveJob associated</span></span><br><span class="line">  <span class="comment">// with this Stage</span></span><br><span class="line">  <span class="keyword">val</span> properties = jobIdToActiveJob(jobId).properties</span><br><span class="line"></span><br><span class="line">  runningStages += stage</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 2. 通知OutputCommitCoordinator要启动stage</span></span><br><span class="line">  stage <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">      outputCommitCoordinator.stageStart(</span><br><span class="line">        stage = s.id, maxPartitionId = s.rdd.partitions.length - <span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 3. 为每个分区计算相应的TaskLocation</span></span><br><span class="line">  <span class="keyword">val</span> taskIdToLocations: <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">TaskLocation</span>]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> p = s.partitions(id)</span><br><span class="line">          (id, getPreferredLocs(stage.rdd, p))</span><br><span class="line">        &#125;.toMap</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)</span><br><span class="line">      listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 4. 创建StageInfo作为一次stage attempt</span></span><br><span class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If there are tasks to execute, record the submission time of the stage. Otherwise,</span></span><br><span class="line">  <span class="comment">// post the even without the submission time, which indicates that this stage was</span></span><br><span class="line">  <span class="comment">// skipped.</span></span><br><span class="line">  <span class="keyword">if</span> (partitionsToCompute.nonEmpty) &#123;</span><br><span class="line">    stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</span><br><span class="line">  &#125;</span><br><span class="line">  listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 5. 序列化stage相关信息作为task的二进制数据，并将其广播</span></span><br><span class="line">  <span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> partitions: <span class="type">Array</span>[<span class="type">Partition</span>] = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></span><br><span class="line">    <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></span><br><span class="line">    <span class="keyword">var</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = <span class="literal">null</span></span><br><span class="line">    <span class="comment">// taskBinaryBytes and partitions are both effected by the checkpoint status. We need</span></span><br><span class="line">    <span class="comment">// this synchronization in case another concurrent job is checkpointing this RDD, so we get a</span></span><br><span class="line">    <span class="comment">// consistent view of both variables.</span></span><br><span class="line">    <span class="type">RDDCheckpointData</span>.synchronized &#123;</span><br><span class="line">      taskBinaryBytes = stage <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">          <span class="type">JavaUtils</span>.bufferToArray(</span><br><span class="line">            closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>))</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">          <span class="type">JavaUtils</span>.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>))</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      partitions = stage.rdd.partitions</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    taskBinary = sc.broadcast(taskBinaryBytes)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="comment">// In the case of a failure during serialization, abort the stage.</span></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">NotSerializableException</span> =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">&quot;Task not serializable: &quot;</span> + e.toString, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Abort execution</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task serialization failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Abort execution</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 6. 为每个分区创建一个Task对象</span></span><br><span class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> serializedTaskMetrics = closureSerializer.serialize(stage.latestInfo.taskMetrics).array()</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        stage.pendingPartitions.clear()</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(id)</span><br><span class="line">          stage.pendingPartitions += id</span><br><span class="line">          <span class="comment">//对于ShuffleMapStage，为每个分区创建ShuffleMapTask</span></span><br><span class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, properties, serializedTaskMetrics, <span class="type">Option</span>(jobId),</span><br><span class="line">            <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(p)</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="comment">//对于ResultStage，为每个分区创建ResultTask</span></span><br><span class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, id, properties, serializedTaskMetrics,</span><br><span class="line">            <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId,</span><br><span class="line">            stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 7. 将上面创建的Task集合提交至TaskScheduler</span></span><br><span class="line">  <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    logInfo(<span class="string">s&quot;Submitting <span class="subst">$&#123;tasks.size&#125;</span> missing tasks from <span class="subst">$stage</span> (<span class="subst">$&#123;stage.rdd&#125;</span>) (first 15 &quot;</span> +</span><br><span class="line">      <span class="string">s&quot;tasks are for partitions <span class="subst">$&#123;tasks.take(15).map(_.partitionId)&#125;</span>)&quot;</span>)</span><br><span class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Because we posted SparkListenerStageSubmitted earlier, we should mark</span></span><br><span class="line">    <span class="comment">// the stage as completed here in case there are no tasks to run</span></span><br><span class="line">    markStageAsFinished(stage, <span class="type">None</span>)</span><br><span class="line"></span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        logDebug(<span class="string">s&quot;Stage <span class="subst">$&#123;stage&#125;</span> is actually done; &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;(available: <span class="subst">$&#123;stage.isAvailable&#125;</span>,&quot;</span> +</span><br><span class="line">            <span class="string">s&quot;available outputs: <span class="subst">$&#123;stage.numAvailableOutputs&#125;</span>,&quot;</span> +</span><br><span class="line">            <span class="string">s&quot;partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)&quot;</span>)</span><br><span class="line">        markMapStageJobsAsFinished(stage)</span><br><span class="line">      <span class="keyword">case</span> stage : <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        logDebug(<span class="string">s&quot;Stage <span class="subst">$&#123;stage&#125;</span> is actually done; (partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    submitWaitingChildStages(stage)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 为rdd的特定分区查找优先位置，</span></span><br><span class="line"><span class="comment"> * 有三种数据策略：</span></span><br><span class="line"><span class="comment"> * 1. 如果该rdd已经缓存过了，直接使用缓存数据地址；</span></span><br><span class="line"><span class="comment"> * 2. 否则，使用RDD级别定义的数据策略；</span></span><br><span class="line"><span class="comment"> * 3. 否则，使用当前stage中该rdd上游RDD中第一个数据策略可用的策略；</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getPreferredLocsInternal</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_],</span><br><span class="line">    partition: <span class="type">Int</span>,</span><br><span class="line">    visited: <span class="type">HashSet</span>[(<span class="type">RDD</span>[_], <span class="type">Int</span>)]): <span class="type">Seq</span>[<span class="type">TaskLocation</span>] = &#123;</span><br><span class="line">  <span class="comment">// If the partition has already been visited, no need to re-visit.</span></span><br><span class="line">  <span class="comment">// This avoids exponential path exploration.  SPARK-695</span></span><br><span class="line">  <span class="keyword">if</span> (!visited.add((rdd, partition))) &#123;</span><br><span class="line">    <span class="comment">// Nil has already been returned for previously visited partitions.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="type">Nil</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// If the partition is cached, return the cache locations</span></span><br><span class="line">  <span class="keyword">val</span> cached = getCacheLocs(rdd)(partition)</span><br><span class="line">  <span class="keyword">if</span> (cached.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">return</span> cached</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// If the RDD has some placement preferences (as is the case for input RDDs), get those</span></span><br><span class="line">  <span class="keyword">val</span> rddPrefs = rdd.preferredLocations(rdd.partitions(partition)).toList</span><br><span class="line">  <span class="keyword">if</span> (rddPrefs.nonEmpty) &#123;</span><br><span class="line">    <span class="keyword">return</span> rddPrefs.map(<span class="type">TaskLocation</span>(_))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If the RDD has narrow dependencies, pick the first partition of the first narrow dependency</span></span><br><span class="line">  <span class="comment">// that has any placement preferences. Ideally we would choose based on transfer sizes,</span></span><br><span class="line">  <span class="comment">// but this will do for now.</span></span><br><span class="line">  rdd.dependencies.foreach &#123;</span><br><span class="line">    <span class="keyword">case</span> n: <span class="type">NarrowDependency</span>[_] =&gt;</span><br><span class="line">      <span class="keyword">for</span> (inPart &lt;- n.getParents(partition)) &#123;</span><br><span class="line">        <span class="keyword">val</span> locs = getPreferredLocsInternal(n.rdd, inPart, visited)</span><br><span class="line">        <span class="keyword">if</span> (locs != <span class="type">Nil</span>) &#123;</span><br><span class="line">          <span class="keyword">return</span> locs</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> _ =&gt;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">Nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="TaskSchedulerImpl"><a href="#TaskSchedulerImpl" class="headerlink" title="TaskSchedulerImpl"></a>TaskSchedulerImpl</h1><p>该类是面向任务的，它将任务在不同类型的集群上进行调度。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// key为stageId，value中的key为stageAttemptId，value中的value为TaskSetManager</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> taskSetsByStageIdAndAttempt = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> schedulableBuilder: <span class="type">SchedulableBuilder</span> = <span class="literal">null</span></span><br><span class="line"><span class="keyword">val</span> rootPool: <span class="type">Pool</span> = <span class="keyword">new</span> <span class="type">Pool</span>(<span class="string">&quot;&quot;</span>, schedulingMode, <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>



<h2 id="提交任务-1"><a href="#提交任务-1" class="headerlink" title="提交任务"></a>提交任务</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">submitTasks</span></span>(taskSet: <span class="type">TaskSet</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> tasks = taskSet.tasks</span><br><span class="line">  logInfo(<span class="string">&quot;Adding task set &quot;</span> + taskSet.id + <span class="string">&quot; with &quot;</span> + tasks.length + <span class="string">&quot; tasks&quot;</span>)</span><br><span class="line">  <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    <span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</span><br><span class="line">    <span class="keyword">val</span> stage = taskSet.stageId</span><br><span class="line">    <span class="keyword">val</span> stageTaskSets =</span><br><span class="line">      taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Mark all the existing TaskSetManagers of this stage as zombie, as we are adding a new one.</span></span><br><span class="line">    <span class="comment">// This is necessary to handle a corner case. Let&#x27;s say a stage has 10 partitions and has 2</span></span><br><span class="line">    <span class="comment">// TaskSetManagers: TSM1(zombie) and TSM2(active). TSM1 has a running task for partition 10</span></span><br><span class="line">    <span class="comment">// and it completes. TSM2 finishes tasks for partition 1-9, and thinks he is still active</span></span><br><span class="line">    <span class="comment">// because partition 10 is not completed yet. However, DAGScheduler gets task completion</span></span><br><span class="line">    <span class="comment">// events for all the 10 partitions and thinks the stage is finished. If it&#x27;s a shuffle stage</span></span><br><span class="line">    <span class="comment">// and somehow it has missing map outputs, then DAGScheduler will resubmit it and create a</span></span><br><span class="line">    <span class="comment">// TSM3 for it. As a stage can&#x27;t have more than one active task set managers, we must mark</span></span><br><span class="line">    <span class="comment">// TSM2 as zombie (it actually is).</span></span><br><span class="line">    stageTaskSets.foreach &#123; <span class="keyword">case</span> (_, ts) =&gt;</span><br><span class="line">      ts.isZombie = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    stageTaskSets(taskSet.stageAttemptId) = manager</span><br><span class="line">    schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;</span><br><span class="line">      starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">TimerTask</span>() &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">          <span class="keyword">if</span> (!hasLaunchedTask) &#123;</span><br><span class="line">            logWarning(<span class="string">&quot;Initial job has not accepted any resources; &quot;</span> +</span><br><span class="line">              <span class="string">&quot;check your cluster UI to ensure that workers are registered &quot;</span> +</span><br><span class="line">              <span class="string">&quot;and have sufficient resources&quot;</span>)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.cancel()</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;, <span class="type">STARVATION_TIMEOUT_MS</span>, <span class="type">STARVATION_TIMEOUT_MS</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    hasReceivedTask = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">  backend.reviveOffers()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 为每个TaskSet创建TaskSetManager</span></span><br><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">createTaskSetManager</span></span>(</span><br><span class="line">    taskSet: <span class="type">TaskSet</span>,</span><br><span class="line">    maxTaskFailures: <span class="type">Int</span>): <span class="type">TaskSetManager</span> = &#123;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">TaskSetManager</span>(<span class="keyword">this</span>, taskSet, maxTaskFailures, blacklistTrackerOpt)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="分配任务"><a href="#分配任务" class="headerlink" title="分配任务"></a>分配任务</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 向executor资源分配任务</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resourceOffers</span></span>(offers: <span class="type">IndexedSeq</span>[<span class="type">WorkerOffer</span>]): <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]] = synchronized &#123;</span><br><span class="line">  <span class="comment">// 1.对executor资源记账</span></span><br><span class="line">  <span class="keyword">var</span> newExecAvail = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">for</span> (o &lt;- offers) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!hostToExecutors.contains(o.host)) &#123;</span><br><span class="line">      hostToExecutors(o.host) = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!executorIdToRunningTaskIds.contains(o.executorId)) &#123;</span><br><span class="line">      hostToExecutors(o.host) += o.executorId</span><br><span class="line">      executorAdded(o.executorId, o.host)</span><br><span class="line">      executorIdToHost(o.executorId) = o.host</span><br><span class="line">      executorIdToRunningTaskIds(o.executorId) = <span class="type">HashSet</span>[<span class="type">Long</span>]()</span><br><span class="line">      newExecAvail = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (rack &lt;- getRackForHost(o.host)) &#123;</span><br><span class="line">      hostsByRack.getOrElseUpdate(rack, <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">String</span>]()) += o.host</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2. 过滤并对资源进行shuffle</span></span><br><span class="line">  <span class="comment">// 将黑名单过时的主机进行移除</span></span><br><span class="line">  blacklistTrackerOpt.foreach(_.applyBlacklistTimeout())</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> filteredOffers = blacklistTrackerOpt.map &#123; blacklistTracker =&gt;</span><br><span class="line">    offers.filter &#123; offer =&gt;</span><br><span class="line">      !blacklistTracker.isNodeBlacklisted(offer.host) &amp;&amp;</span><br><span class="line">        !blacklistTracker.isExecutorBlacklisted(offer.executorId)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;.getOrElse(offers)</span><br><span class="line">  <span class="comment">// 对资源进行shuffle操作</span></span><br><span class="line">  <span class="keyword">val</span> shuffledOffers = shuffleOffers(filteredOffers)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 3.根据executor资源，构建本轮次的任务列表</span></span><br><span class="line">  <span class="keyword">val</span> tasks = shuffledOffers.map(o =&gt; <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>](o.cores / <span class="type">CPUS_PER_TASK</span>))</span><br><span class="line">  <span class="keyword">val</span> availableCpus = shuffledOffers.map(o =&gt; o.cores).toArray</span><br><span class="line">  <span class="keyword">val</span> availableSlots = shuffledOffers.map(o =&gt; o.cores / <span class="type">CPUS_PER_TASK</span>).sum</span><br><span class="line">  <span class="keyword">val</span> sortedTaskSets = rootPool.getSortedTaskSetQueue</span><br><span class="line">  <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets) &#123;</span><br><span class="line">    logDebug(<span class="string">&quot;parentName: %s, name: %s, runningTasks: %s&quot;</span>.format(</span><br><span class="line">      taskSet.parent.name, taskSet.name, taskSet.runningTasks))</span><br><span class="line">    <span class="keyword">if</span> (newExecAvail) &#123; <span class="comment">// 如果有新的executor可使用，那么对taskset的本地性重新计算</span></span><br><span class="line">      taskSet.executorAdded()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 4.按照TaskSet的调度顺序，将TaskSet任务分配到executor资源执行</span></span><br><span class="line">  <span class="keyword">for</span> (taskSet &lt;- sortedTaskSets) &#123;</span><br><span class="line">    <span class="comment">// Skip the barrier taskSet if the available slots are less than the number of pending tasks.</span></span><br><span class="line">    <span class="keyword">if</span> (taskSet.isBarrier &amp;&amp; availableSlots &lt; taskSet.numTasks) &#123;</span><br><span class="line">      <span class="comment">// Skip the launch process.</span></span><br><span class="line">      <span class="comment">// TODO SPARK-24819 If the job requires more slots than available (both busy and free</span></span><br><span class="line">      <span class="comment">// slots), fail the job on submit.</span></span><br><span class="line">      logInfo(<span class="string">s&quot;Skip current round of resource offers for barrier stage <span class="subst">$&#123;taskSet.stageId&#125;</span> &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;because the barrier taskSet requires <span class="subst">$&#123;taskSet.numTasks&#125;</span> slots, while the total &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;number of available slots is <span class="subst">$availableSlots</span>.&quot;</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">var</span> launchedAnyTask = <span class="literal">false</span></span><br><span class="line">      <span class="comment">// Record all the executor IDs assigned barrier tasks on.</span></span><br><span class="line">      <span class="keyword">val</span> addressesWithDescs = <span class="type">ArrayBuffer</span>[(<span class="type">String</span>, <span class="type">TaskDescription</span>)]()</span><br><span class="line">      <span class="comment">// 4.1 按本地性依次递增的顺序，将taskSet的任务分配到executor上</span></span><br><span class="line">      <span class="comment">// 本地性依次递增：PROCESS_LOCAL, NODE_LOCAL, NO_PREF, RACK_LOCAL, ANY</span></span><br><span class="line">      <span class="keyword">for</span> (currentMaxLocality &lt;- taskSet.myLocalityLevels) &#123;</span><br><span class="line">        <span class="keyword">var</span> launchedTaskAtCurrentMaxLocality = <span class="literal">false</span></span><br><span class="line">        do &#123;</span><br><span class="line">          launchedTaskAtCurrentMaxLocality = resourceOfferSingleTaskSet(taskSet,</span><br><span class="line">            currentMaxLocality, shuffledOffers, availableCpus, tasks, addressesWithDescs)</span><br><span class="line">          launchedAnyTask |= launchedTaskAtCurrentMaxLocality</span><br><span class="line">        &#125; <span class="keyword">while</span> (launchedTaskAtCurrentMaxLocality)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (!launchedAnyTask) &#123;</span><br><span class="line">        taskSet.getCompletelyBlacklistedTaskIfAny(hostToExecutors).foreach &#123; taskIndex =&gt;</span><br><span class="line">            <span class="comment">// If the taskSet is unschedulable we try to find an existing idle blacklisted</span></span><br><span class="line">            <span class="comment">// executor. If we cannot find one, we abort immediately. Else we kill the idle</span></span><br><span class="line">            <span class="comment">// executor and kick off an abortTimer which if it doesn&#x27;t schedule a task within the</span></span><br><span class="line">            <span class="comment">// the timeout will abort the taskSet if we were unable to schedule any task from the</span></span><br><span class="line">            <span class="comment">// taskSet.</span></span><br><span class="line">            <span class="comment">// Note 1: We keep track of schedulability on a per taskSet basis rather than on a per</span></span><br><span class="line">            <span class="comment">// task basis.</span></span><br><span class="line">            <span class="comment">// Note 2: The taskSet can still be aborted when there are more than one idle</span></span><br><span class="line">            <span class="comment">// blacklisted executors and dynamic allocation is on. This can happen when a killed</span></span><br><span class="line">            <span class="comment">// idle executor isn&#x27;t replaced in time by ExecutorAllocationManager as it relies on</span></span><br><span class="line">            <span class="comment">// pending tasks and doesn&#x27;t kill executors on idle timeouts, resulting in the abort</span></span><br><span class="line">            <span class="comment">// timer to expire and abort the taskSet.</span></span><br><span class="line">            executorIdToRunningTaskIds.find(x =&gt; !isExecutorBusy(x._1)) <span class="keyword">match</span> &#123;</span><br><span class="line">              <span class="keyword">case</span> <span class="type">Some</span> ((executorId, _)) =&gt;</span><br><span class="line">                <span class="keyword">if</span> (!unschedulableTaskSetToExpiryTime.contains(taskSet)) &#123;</span><br><span class="line">                  blacklistTrackerOpt.foreach(blt =&gt; blt.killBlacklistedIdleExecutor(executorId))</span><br><span class="line"></span><br><span class="line">                  <span class="keyword">val</span> timeout = conf.get(config.<span class="type">UNSCHEDULABLE_TASKSET_TIMEOUT</span>) * <span class="number">1000</span></span><br><span class="line">                  unschedulableTaskSetToExpiryTime(taskSet) = clock.getTimeMillis() + timeout</span><br><span class="line">                  logInfo(<span class="string">s&quot;Waiting for <span class="subst">$timeout</span> ms for completely &quot;</span></span><br><span class="line">                    + <span class="string">s&quot;blacklisted task to be schedulable again before aborting <span class="subst">$taskSet</span>.&quot;</span>)</span><br><span class="line">                  abortTimer.schedule(</span><br><span class="line">                    createUnschedulableTaskSetAbortTimer(taskSet, taskIndex), timeout)</span><br><span class="line">                &#125;</span><br><span class="line">              <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="comment">// Abort Immediately</span></span><br><span class="line">                logInfo(<span class="string">&quot;Cannot schedule any task because of complete blacklisting. No idle&quot;</span> +</span><br><span class="line">                  <span class="string">s&quot; executors can be found to kill. Aborting <span class="subst">$taskSet</span>.&quot;</span> )</span><br><span class="line">                taskSet.abortSinceCompletelyBlacklisted(taskIndex)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// We want to defer killing any taskSets as long as we have a non blacklisted executor</span></span><br><span class="line">        <span class="comment">// which can be used to schedule a task from any active taskSets. This ensures that the</span></span><br><span class="line">        <span class="comment">// job can make progress.</span></span><br><span class="line">        <span class="comment">// Note: It is theoretically possible that a taskSet never gets scheduled on a</span></span><br><span class="line">        <span class="comment">// non-blacklisted executor and the abort timer doesn&#x27;t kick in because of a constant</span></span><br><span class="line">        <span class="comment">// submission of new TaskSets. See the PR for more details.</span></span><br><span class="line">        <span class="keyword">if</span> (unschedulableTaskSetToExpiryTime.nonEmpty) &#123;</span><br><span class="line">          logInfo(<span class="string">&quot;Clearing the expiry times for all unschedulable taskSets as a task was &quot;</span> +</span><br><span class="line">            <span class="string">&quot;recently scheduled.&quot;</span>)</span><br><span class="line">          unschedulableTaskSetToExpiryTime.clear()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (launchedAnyTask &amp;&amp; taskSet.isBarrier) &#123;</span><br><span class="line">        <span class="comment">// Check whether the barrier tasks are partially launched.</span></span><br><span class="line">        <span class="comment">// TODO SPARK-24818 handle the assert failure case (that can happen when some locality</span></span><br><span class="line">        <span class="comment">// requirements are not fulfilled, and we should revert the launched tasks).</span></span><br><span class="line">        require(addressesWithDescs.size == taskSet.numTasks,</span><br><span class="line">          <span class="string">s&quot;Skip current round of resource offers for barrier stage <span class="subst">$&#123;taskSet.stageId&#125;</span> &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;because only <span class="subst">$&#123;addressesWithDescs.size&#125;</span> out of a total number of &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;<span class="subst">$&#123;taskSet.numTasks&#125;</span> tasks got resource offers. The resource offers may have &quot;</span> +</span><br><span class="line">            <span class="string">&quot;been blacklisted or cannot fulfill task locality requirements.&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// materialize the barrier coordinator.</span></span><br><span class="line">        maybeInitBarrierCoordinator()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Update the taskInfos into all the barrier task properties.</span></span><br><span class="line">        <span class="keyword">val</span> addressesStr = addressesWithDescs</span><br><span class="line">          <span class="comment">// Addresses ordered by partitionId</span></span><br><span class="line">          .sortBy(_._2.partitionId)</span><br><span class="line">          .map(_._1)</span><br><span class="line">          .mkString(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">        addressesWithDescs.foreach(_._2.properties.setProperty(<span class="string">&quot;addresses&quot;</span>, addressesStr))</span><br><span class="line"></span><br><span class="line">        logInfo(<span class="string">s&quot;Successfully scheduled all the <span class="subst">$&#123;addressesWithDescs.size&#125;</span> tasks for barrier &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;stage <span class="subst">$&#123;taskSet.stageId&#125;</span>.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO SPARK-24823 Cancel a job that contains barrier stage(s) if the barrier tasks don&#x27;t get</span></span><br><span class="line">  <span class="comment">// launched within a configured time.</span></span><br><span class="line">  <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    hasLaunchedTask = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> tasks</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将TaskSetManager的任务分配到executor资源上</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">resourceOfferSingleTaskSet</span></span>(</span><br><span class="line">    taskSet: <span class="type">TaskSetManager</span>,</span><br><span class="line">    maxLocality: <span class="type">TaskLocality</span>,</span><br><span class="line">    shuffledOffers: <span class="type">Seq</span>[<span class="type">WorkerOffer</span>],</span><br><span class="line">    availableCpus: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">    tasks: <span class="type">IndexedSeq</span>[<span class="type">ArrayBuffer</span>[<span class="type">TaskDescription</span>]],</span><br><span class="line">    addressesWithDescs: <span class="type">ArrayBuffer</span>[(<span class="type">String</span>, <span class="type">TaskDescription</span>)]) : <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> launchedTask = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//对于资源采用round-robin的方式进行分配任务</span></span><br><span class="line">  <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until shuffledOffers.size) &#123;</span><br><span class="line">    <span class="keyword">val</span> execId = shuffledOffers(i).executorId</span><br><span class="line">    <span class="keyword">val</span> host = shuffledOffers(i).host</span><br><span class="line">    <span class="keyword">if</span> (availableCpus(i) &gt;= <span class="type">CPUS_PER_TASK</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// taskSet.resourceOffer()会为一个executor分配一个任务</span></span><br><span class="line">        <span class="keyword">for</span> (task &lt;- taskSet.resourceOffer(execId, host, maxLocality)) &#123;</span><br><span class="line">          tasks(i) += task</span><br><span class="line">          <span class="keyword">val</span> tid = task.taskId</span><br><span class="line">          taskIdToTaskSetManager.put(tid, taskSet)</span><br><span class="line">          taskIdToExecutorId(tid) = execId</span><br><span class="line">          executorIdToRunningTaskIds(execId).add(tid)</span><br><span class="line">          availableCpus(i) -= <span class="type">CPUS_PER_TASK</span></span><br><span class="line">          assert(availableCpus(i) &gt;= <span class="number">0</span>)</span><br><span class="line">          <span class="comment">// Only update hosts for a barrier task.</span></span><br><span class="line">          <span class="keyword">if</span> (taskSet.isBarrier) &#123;</span><br><span class="line">            <span class="comment">// The executor address is expected to be non empty.</span></span><br><span class="line">            addressesWithDescs += (shuffledOffers(i).address.get -&gt; task)</span><br><span class="line">          &#125;</span><br><span class="line">          launchedTask = <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">TaskNotSerializableException</span> =&gt;</span><br><span class="line">          logError(<span class="string">s&quot;Resource offer failed, task set <span class="subst">$&#123;taskSet.name&#125;</span> was not serializable&quot;</span>)</span><br><span class="line">          <span class="comment">// Do not offer resources for this task, but don&#x27;t throw an error to allow other</span></span><br><span class="line">          <span class="comment">// task sets to be submitted.</span></span><br><span class="line">          <span class="keyword">return</span> launchedTask</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> launchedTask</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="追踪任务状态"><a href="#追踪任务状态" class="headerlink" title="追踪任务状态"></a>追踪任务状态</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">statusUpdate</span></span>(tid: <span class="type">Long</span>, state: <span class="type">TaskState</span>, serializedData: <span class="type">ByteBuffer</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> failedExecutor: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></span><br><span class="line">  <span class="keyword">var</span> reason: <span class="type">Option</span>[<span class="type">ExecutorLossReason</span>] = <span class="type">None</span></span><br><span class="line">  synchronized &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="type">Option</span>(taskIdToTaskSetManager.get(tid)) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(taskSet) =&gt;</span><br><span class="line">          <span class="keyword">if</span> (state == <span class="type">TaskState</span>.<span class="type">LOST</span>) &#123;</span><br><span class="line">            <span class="comment">// TaskState.LOST is only used by the deprecated Mesos fine-grained scheduling mode,</span></span><br><span class="line">            <span class="comment">// where each executor corresponds to a single task, so mark the executor as failed.</span></span><br><span class="line">            <span class="keyword">val</span> execId = taskIdToExecutorId.getOrElse(tid, <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(</span><br><span class="line">              <span class="string">&quot;taskIdToTaskSetManager.contains(tid) &lt;=&gt; taskIdToExecutorId.contains(tid)&quot;</span>))</span><br><span class="line">            <span class="keyword">if</span> (executorIdToRunningTaskIds.contains(execId)) &#123;</span><br><span class="line">              reason = <span class="type">Some</span>(</span><br><span class="line">                <span class="type">SlaveLost</span>(<span class="string">s&quot;Task <span class="subst">$tid</span> was lost, so marking the executor as lost as well.&quot;</span>))</span><br><span class="line">              removeExecutor(execId, reason.get)</span><br><span class="line">              failedExecutor = <span class="type">Some</span>(execId)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (<span class="type">TaskState</span>.isFinished(state)) &#123;</span><br><span class="line">            cleanupTaskState(tid)</span><br><span class="line">            taskSet.removeRunningTask(tid)</span><br><span class="line">            <span class="keyword">if</span> (state == <span class="type">TaskState</span>.<span class="type">FINISHED</span>) &#123;</span><br><span class="line">              taskResultGetter.enqueueSuccessfulTask(taskSet, tid, serializedData)</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="type">Set</span>(<span class="type">TaskState</span>.<span class="type">FAILED</span>, <span class="type">TaskState</span>.<span class="type">KILLED</span>, <span class="type">TaskState</span>.<span class="type">LOST</span>).contains(state)) &#123;</span><br><span class="line">              taskResultGetter.enqueueFailedTask(taskSet, tid, state, serializedData)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">          logError(</span><br><span class="line">            (<span class="string">&quot;Ignoring update with state %s for TID %s because its task set is gone (this is &quot;</span> +</span><br><span class="line">              <span class="string">&quot;likely the result of receiving duplicate task finished status updates) or its &quot;</span> +</span><br><span class="line">              <span class="string">&quot;executor has been marked as failed.&quot;</span>)</span><br><span class="line">              .format(state, tid))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; logError(<span class="string">&quot;Exception in statusUpdate&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Update the DAGScheduler without holding a lock on this, since that can deadlock</span></span><br><span class="line">  <span class="keyword">if</span> (failedExecutor.isDefined) &#123;</span><br><span class="line">    assert(reason.isDefined)</span><br><span class="line">    dagScheduler.executorLost(failedExecutor.get, reason.get)</span><br><span class="line">    backend.reviveOffers()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="TaskSetManager"><a href="#TaskSetManager" class="headerlink" title="TaskSetManager"></a>TaskSetManager</h2><p>它继承了Schedulable接口，</p>
<p>在内部，</p>
<p>该类负责追踪TaskSet中的每个任务、如果任务失败对任务进行重试、以及处理为TaskSet进行位置感知的调度。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 所有等待执行的任务，该结构作为堆栈的形式使用</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> allPendingTasks = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Int</span>]</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将指定索引的任务添加到allPendingTasks，</span></span><br><span class="line"><span class="comment"> * 其中对于有优先位置的任务，添加相应的记录到pendingTasksForExecutor、pendingTasksForHost和pendingTasksForRack；</span></span><br><span class="line"><span class="comment"> * 对于没有优先位置信息的任务，添加相应记录到pendingTasksWithNoPrefs</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">addPendingTask</span></span>(index: <span class="type">Int</span>) &#123;</span><br><span class="line">  <span class="keyword">for</span> (loc &lt;- tasks(index).preferredLocations) &#123;</span><br><span class="line">    loc <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">ExecutorCacheTaskLocation</span> =&gt;</span><br><span class="line">        pendingTasksForExecutor.getOrElseUpdate(e.executorId, <span class="keyword">new</span> <span class="type">ArrayBuffer</span>) += index</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">HDFSCacheTaskLocation</span> =&gt;</span><br><span class="line">        <span class="keyword">val</span> exe = sched.getExecutorsAliveOnHost(loc.host)</span><br><span class="line">        exe <span class="keyword">match</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> <span class="type">Some</span>(set) =&gt;</span><br><span class="line">            <span class="keyword">for</span> (e &lt;- set) &#123;</span><br><span class="line">              pendingTasksForExecutor.getOrElseUpdate(e, <span class="keyword">new</span> <span class="type">ArrayBuffer</span>) += index</span><br><span class="line">            &#125;</span><br><span class="line">            logInfo(<span class="string">s&quot;Pending task <span class="subst">$index</span> has a cached location at <span class="subst">$&#123;e.host&#125;</span> &quot;</span> +</span><br><span class="line">              <span class="string">&quot;, where there are executors &quot;</span> + set.mkString(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">          <span class="keyword">case</span> <span class="type">None</span> =&gt; logDebug(<span class="string">s&quot;Pending task <span class="subst">$index</span> has a cached location at <span class="subst">$&#123;e.host&#125;</span> &quot;</span> +</span><br><span class="line">              <span class="string">&quot;, but there are no executors alive there.&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">    &#125;</span><br><span class="line">    pendingTasksForHost.getOrElseUpdate(loc.host, <span class="keyword">new</span> <span class="type">ArrayBuffer</span>) += index</span><br><span class="line">    <span class="keyword">for</span> (rack &lt;- sched.getRackForHost(loc.host)) &#123;</span><br><span class="line">      pendingTasksForRack.getOrElseUpdate(rack, <span class="keyword">new</span> <span class="type">ArrayBuffer</span>) += index</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (tasks(index).preferredLocations == <span class="type">Nil</span>) &#123;</span><br><span class="line">    pendingTasksWithNoPrefs += index</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  allPendingTasks += index  <span class="comment">// No point scanning this whole list to find the old task there</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 为一个executor分配一个任务</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resourceOffer</span></span>(</span><br><span class="line">    execId: <span class="type">String</span>,</span><br><span class="line">    host: <span class="type">String</span>,</span><br><span class="line">    maxLocality: <span class="type">TaskLocality</span>.<span class="type">TaskLocality</span>)</span><br><span class="line">  : <span class="type">Option</span>[<span class="type">TaskDescription</span>] =</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">val</span> offerBlacklisted = taskSetBlacklistHelperOpt.exists &#123; blacklist =&gt;</span><br><span class="line">    blacklist.isNodeBlacklistedForTaskSet(host) ||</span><br><span class="line">      blacklist.isExecutorBlacklistedForTaskSet(execId)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!isZombie &amp;&amp; !offerBlacklisted) &#123;</span><br><span class="line">    <span class="keyword">val</span> curTime = clock.getTimeMillis()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> allowedLocality = maxLocality</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</span><br><span class="line">      allowedLocality = getAllowedLocalityLevel(curTime)</span><br><span class="line">      <span class="keyword">if</span> (allowedLocality &gt; maxLocality) &#123;</span><br><span class="line">        <span class="comment">// We&#x27;re not allowed to search for farther-away tasks</span></span><br><span class="line">        allowedLocality = maxLocality</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    dequeueTask(execId, host, allowedLocality).map &#123; <span class="keyword">case</span> ((index, taskLocality, speculative)) =&gt;</span><br><span class="line">      <span class="comment">// Found a task; do some bookkeeping and return a task description</span></span><br><span class="line">      <span class="keyword">val</span> task = tasks(index)</span><br><span class="line">      <span class="keyword">val</span> taskId = sched.newTaskId()</span><br><span class="line">      <span class="comment">// Do various bookkeeping</span></span><br><span class="line">      copiesRunning(index) += <span class="number">1</span></span><br><span class="line">      <span class="keyword">val</span> attemptNum = taskAttempts(index).size</span><br><span class="line">      <span class="keyword">val</span> info = <span class="keyword">new</span> <span class="type">TaskInfo</span>(taskId, index, attemptNum, curTime,</span><br><span class="line">        execId, host, taskLocality, speculative)</span><br><span class="line">      taskInfos(taskId) = info</span><br><span class="line">      taskAttempts(index) = info :: taskAttempts(index)</span><br><span class="line">      <span class="comment">// Update our locality level for delay scheduling</span></span><br><span class="line">      <span class="comment">// NO_PREF will not affect the variables related to delay scheduling</span></span><br><span class="line">      <span class="keyword">if</span> (maxLocality != <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>) &#123;</span><br><span class="line">        currentLocalityIndex = getLocalityIndex(taskLocality)</span><br><span class="line">        lastLaunchTime = curTime</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Serialize and return the task</span></span><br><span class="line">      <span class="keyword">val</span> serializedTask: <span class="type">ByteBuffer</span> = <span class="keyword">try</span> &#123;</span><br><span class="line">        ser.serialize(task)</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="comment">// If the task cannot be serialized, then there&#x27;s no point to re-attempt the task,</span></span><br><span class="line">        <span class="comment">// as it will always fail. So just abort the whole task-set.</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">          <span class="keyword">val</span> msg = <span class="string">s&quot;Failed to serialize task <span class="subst">$taskId</span>, not attempting to retry it.&quot;</span></span><br><span class="line">          logError(msg, e)</span><br><span class="line">          abort(<span class="string">s&quot;<span class="subst">$msg</span> Exception during serialization: <span class="subst">$e</span>&quot;</span>)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TaskNotSerializableException</span>(e)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (serializedTask.limit() &gt; <span class="type">TaskSetManager</span>.<span class="type">TASK_SIZE_TO_WARN_KB</span> * <span class="number">1024</span> &amp;&amp;</span><br><span class="line">        !emittedTaskSizeWarning) &#123;</span><br><span class="line">        emittedTaskSizeWarning = <span class="literal">true</span></span><br><span class="line">        logWarning(<span class="string">s&quot;Stage <span class="subst">$&#123;task.stageId&#125;</span> contains a task of very large size &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;(<span class="subst">$&#123;serializedTask.limit() / 1024&#125;</span> KB). The maximum recommended task size is &quot;</span> +</span><br><span class="line">          <span class="string">s&quot;<span class="subst">$&#123;TaskSetManager.TASK_SIZE_TO_WARN_KB&#125;</span> KB.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      addRunningTask(taskId)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// We used to log the time it takes to serialize the task, but task size is already</span></span><br><span class="line">      <span class="comment">// a good proxy to task serialization time.</span></span><br><span class="line">      <span class="comment">// val timeTaken = clock.getTime() - startTime</span></span><br><span class="line">      <span class="keyword">val</span> taskName = <span class="string">s&quot;task <span class="subst">$&#123;info.id&#125;</span> in stage <span class="subst">$&#123;taskSet.id&#125;</span>&quot;</span></span><br><span class="line">      logInfo(<span class="string">s&quot;Starting <span class="subst">$taskName</span> (TID <span class="subst">$taskId</span>, <span class="subst">$host</span>, executor <span class="subst">$&#123;info.executorId&#125;</span>, &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;partition <span class="subst">$&#123;task.partitionId&#125;</span>, <span class="subst">$taskLocality</span>, <span class="subst">$&#123;serializedTask.limit()&#125;</span> bytes)&quot;</span>)</span><br><span class="line"></span><br><span class="line">      sched.dagScheduler.taskStarted(task, info)</span><br><span class="line">      <span class="keyword">new</span> <span class="type">TaskDescription</span>(</span><br><span class="line">        taskId,</span><br><span class="line">        attemptNum,</span><br><span class="line">        execId,</span><br><span class="line">        taskName,</span><br><span class="line">        index,</span><br><span class="line">        task.partitionId,</span><br><span class="line">        addedFiles,</span><br><span class="line">        addedJars,</span><br><span class="line">        task.localProperties,</span><br><span class="line">        serializedTask)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment">* </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">dequeueTask</span></span>(execId: <span class="type">String</span>, host: <span class="type">String</span>, maxLocality: <span class="type">TaskLocality</span>.<span class="type">Value</span>)</span><br><span class="line">  : <span class="type">Option</span>[(<span class="type">Int</span>, <span class="type">TaskLocality</span>.<span class="type">Value</span>, <span class="type">Boolean</span>)] =</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (index &lt;- dequeueTaskFromList(execId, host, getPendingTasksForExecutor(execId))) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="type">Some</span>((index, <span class="type">TaskLocality</span>.<span class="type">PROCESS_LOCAL</span>, <span class="literal">false</span>))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="type">TaskLocality</span>.isAllowed(maxLocality, <span class="type">TaskLocality</span>.<span class="type">NODE_LOCAL</span>)) &#123;</span><br><span class="line">    <span class="keyword">for</span> (index &lt;- dequeueTaskFromList(execId, host, getPendingTasksForHost(host))) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="type">Some</span>((index, <span class="type">TaskLocality</span>.<span class="type">NODE_LOCAL</span>, <span class="literal">false</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="type">TaskLocality</span>.isAllowed(maxLocality, <span class="type">TaskLocality</span>.<span class="type">NO_PREF</span>)) &#123;</span><br><span class="line">    <span class="comment">// Look for noPref tasks after NODE_LOCAL for minimize cross-rack traffic</span></span><br><span class="line">    <span class="keyword">for</span> (index &lt;- dequeueTaskFromList(execId, host, pendingTasksWithNoPrefs)) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="type">Some</span>((index, <span class="type">TaskLocality</span>.<span class="type">PROCESS_LOCAL</span>, <span class="literal">false</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="type">TaskLocality</span>.isAllowed(maxLocality, <span class="type">TaskLocality</span>.<span class="type">RACK_LOCAL</span>)) &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">      rack &lt;- sched.getRackForHost(host)</span><br><span class="line">      index &lt;- dequeueTaskFromList(execId, host, getPendingTasksForRack(rack))</span><br><span class="line">    &#125; &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="type">Some</span>((index, <span class="type">TaskLocality</span>.<span class="type">RACK_LOCAL</span>, <span class="literal">false</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="type">TaskLocality</span>.isAllowed(maxLocality, <span class="type">TaskLocality</span>.<span class="type">ANY</span>)) &#123;</span><br><span class="line">    <span class="keyword">for</span> (index &lt;- dequeueTaskFromList(execId, host, allPendingTasks)) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="type">Some</span>((index, <span class="type">TaskLocality</span>.<span class="type">ANY</span>, <span class="literal">false</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// find a speculative task if all others tasks have been scheduled</span></span><br><span class="line">  dequeueSpeculativeTask(execId, host, maxLocality).map &#123;</span><br><span class="line">    <span class="keyword">case</span> (taskIndex, allowedLocality) =&gt; (taskIndex, allowedLocality, <span class="literal">true</span>)&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="CoarseGrainedSchedulerBackend"><a href="#CoarseGrainedSchedulerBackend" class="headerlink" title="CoarseGrainedSchedulerBackend"></a>CoarseGrainedSchedulerBackend</h1><h2 id="DriverEndpoint"><a href="#DriverEndpoint" class="headerlink" title="DriverEndpoint"></a>DriverEndpoint</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeOffers</span></span>() &#123;</span><br><span class="line">  <span class="comment">// Make sure no executor is killed while some task is launching on it</span></span><br><span class="line">  <span class="keyword">val</span> taskDescs = withLock &#123;</span><br><span class="line">    <span class="comment">// Filter out executors under killing</span></span><br><span class="line">    <span class="keyword">val</span> activeExecutors = executorDataMap.filterKeys(executorIsAlive)</span><br><span class="line">    <span class="keyword">val</span> workOffers = activeExecutors.map &#123;</span><br><span class="line">      <span class="keyword">case</span> (id, executorData) =&gt;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">WorkerOffer</span>(id, executorData.executorHost, executorData.freeCores,</span><br><span class="line">          <span class="type">Some</span>(executorData.executorAddress.hostPort))</span><br><span class="line">    &#125;.toIndexedSeq</span><br><span class="line">    <span class="comment">// 将资源提交给TaskSchedulerImpl进行任务分配</span></span><br><span class="line">    scheduler.resourceOffers(workOffers)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!taskDescs.isEmpty) &#123;</span><br><span class="line">    launchTasks(taskDescs) <span class="comment">// 启动任务</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Launch tasks returned by a set of resource offers</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">launchTasks</span></span>(tasks: <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">TaskDescription</span>]]) &#123;</span><br><span class="line">  <span class="keyword">for</span> (task &lt;- tasks.flatten) &#123;</span><br><span class="line">    <span class="keyword">val</span> serializedTask = <span class="type">TaskDescription</span>.encode(task)</span><br><span class="line">    <span class="keyword">if</span> (serializedTask.limit() &gt;= maxRpcMessageSize) &#123;</span><br><span class="line">      <span class="type">Option</span>(scheduler.taskIdToTaskSetManager.get(task.taskId)).foreach &#123; taskSetMgr =&gt;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">var</span> msg = <span class="string">&quot;Serialized task %s:%d was %d bytes, which exceeds max allowed: &quot;</span> +</span><br><span class="line">            <span class="string">&quot;spark.rpc.message.maxSize (%d bytes). Consider increasing &quot;</span> +</span><br><span class="line">            <span class="string">&quot;spark.rpc.message.maxSize or using broadcast variables for large values.&quot;</span></span><br><span class="line">          msg = msg.format(task.taskId, task.index, serializedTask.limit(), maxRpcMessageSize)</span><br><span class="line">          taskSetMgr.abort(msg)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt; logError(<span class="string">&quot;Exception in error callback&quot;</span>, e)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> executorData = executorDataMap(task.executorId)</span><br><span class="line">      executorData.freeCores -= scheduler.<span class="type">CPUS_PER_TASK</span></span><br><span class="line"></span><br><span class="line">      logDebug(<span class="string">s&quot;Launching task <span class="subst">$&#123;task.taskId&#125;</span> on executor id: <span class="subst">$&#123;task.executorId&#125;</span> hostname: &quot;</span> +</span><br><span class="line">        <span class="string">s&quot;<span class="subst">$&#123;executorData.executorHost&#125;</span>.&quot;</span>)</span><br><span class="line"></span><br><span class="line">      executorData.executorEndpoint.send(<span class="type">LaunchTask</span>(<span class="keyword">new</span> <span class="type">SerializableBuffer</span>(serializedTask)))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="CoarseGrainedExecutorBackend"><a href="#CoarseGrainedExecutorBackend" class="headerlink" title="CoarseGrainedExecutorBackend"></a>CoarseGrainedExecutorBackend</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">case</span> <span class="type">LaunchTask</span>(data) =&gt;</span><br><span class="line">    <span class="keyword">if</span> (executor == <span class="literal">null</span>) &#123;</span><br><span class="line">      exitExecutor(<span class="number">1</span>, <span class="string">&quot;Received LaunchTask command but executor was null&quot;</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> taskDesc = <span class="type">TaskDescription</span>.decode(data.value)</span><br><span class="line">      logInfo(<span class="string">&quot;Got assigned task &quot;</span> + taskDesc.taskId)</span><br><span class="line">      executor.launchTask(<span class="keyword">this</span>, taskDesc)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><h1 id="NOTEs"><a href="#NOTEs" class="headerlink" title="NOTEs"></a>NOTEs</h1><p>本文以Spark 2.4.3为基础。</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/21/spark/Spark-cluster-introduction/" rel="prev" title="Spark集群概述">
      <i class="fa fa-chevron-left"></i> Spark集群概述
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/08/28/spark/Spark-RDD-dependency-stage-relation/" rel="next" title="Spark中的RDD、依赖、stage以及它们之间的联系">
      Spark中的RDD、依赖、stage以及它们之间的联系 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



        </div>
        
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JT Li</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/next-boot.js"></script>


  















  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css">

<script>
NexT.utils.loadComments('#gitalk-container', () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'c94aa78cf2eda71757bf',
      clientSecret: '01e1353b3f8eac54aafb1224c784b7af0305ce8c',
      repo        : 'jtLiBrain.github.io',
      owner       : 'jtLiBrain',
      admin       : ['jtLiBrain'],
      id          : '98341729d1c89d2a5d42be0de4c56fb4',
        language: 'en',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
