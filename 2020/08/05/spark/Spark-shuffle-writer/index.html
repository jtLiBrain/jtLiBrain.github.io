<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jtlibrain.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.7.1","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="本篇介绍ShuffleWriter的原理。shuffle任务的运行，请参看此文章。">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark shuffle writer">
<meta property="og:url" content="https://jtlibrain.github.io/2020/08/05/spark/Spark-shuffle-writer/index.html">
<meta property="og:site_name" content="jtLiBrain">
<meta property="og:description" content="本篇介绍ShuffleWriter的原理。shuffle任务的运行，请参看此文章。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/BypassMergeSortShuffleWriter.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/UnsafeShuffleWriter.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/UnsafeShuffleWriter-details.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/ShuffleInMemorySorter-packPointer.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/SortShuffleWriter.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/SortShuffleWriter-details.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/ExternalSorter-mergeSort.svg">
<meta property="og:image" content="https://jtlibrain.github.io/images/spark/AppendOnlyMap-destructiveSortedIterator.svg">
<meta property="article:published_time" content="2020-08-05T08:37:46.000Z">
<meta property="article:modified_time" content="2020-11-29T04:51:07.968Z">
<meta property="article:author" content="JT Li">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jtlibrain.github.io/images/spark/BypassMergeSortShuffleWriter.svg">


<link rel="canonical" href="https://jtlibrain.github.io/2020/08/05/spark/Spark-shuffle-writer/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jtlibrain.github.io/2020/08/05/spark/Spark-shuffle-writer/","path":"2020/08/05/spark/Spark-shuffle-writer/","title":"Spark shuffle writer"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Spark shuffle writer | jtLiBrain</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">jtLiBrain</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">任何伟大的事都不会一蹴而就，三分智慧，七分韧性</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#DiskBlockObjectWriter"><span class="nav-number">1.</span> <span class="nav-text">DiskBlockObjectWriter</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BypassMergeSortShuffleWriter%E5%8E%9F%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">BypassMergeSortShuffleWriter原理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#UnsafeShuffleWriter%E5%8E%9F%E7%90%86"><span class="nav-number">3.</span> <span class="nav-text">UnsafeShuffleWriter原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#TaskMemoryManager"><span class="nav-number">3.1.</span> <span class="nav-text">TaskMemoryManager</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UnsafeShuffleWriter"><span class="nav-number">3.2.</span> <span class="nav-text">UnsafeShuffleWriter</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="nav-number">3.2.1.</span> <span class="nav-text">写入数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%88%E5%B9%B6%E6%96%87%E4%BB%B6"><span class="nav-number">3.2.2.</span> <span class="nav-text">合并文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ShuffleExternalSorter"><span class="nav-number">3.3.</span> <span class="nav-text">ShuffleExternalSorter</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%92%E5%85%A5record%E6%95%B0%E6%8D%AE"><span class="nav-number">3.3.1.</span> <span class="nav-text">插入record数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BA%A2%E5%87%BA"><span class="nav-number">3.3.2.</span> <span class="nav-text">溢出</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ShuffleInMemorySorter"><span class="nav-number">3.4.</span> <span class="nav-text">ShuffleInMemorySorter</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8F%92%E5%85%A5%E8%AE%B0%E5%BD%95%E6%8C%87%E9%92%88"><span class="nav-number">3.4.1.</span> <span class="nav-text">插入记录指针</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%92%E5%BA%8F"><span class="nav-number">3.4.2.</span> <span class="nav-text">排序</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SortShuffleWriter%E5%8E%9F%E7%90%86"><span class="nav-number">4.</span> <span class="nav-text">SortShuffleWriter原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#SortShuffleWriter"><span class="nav-number">4.1.</span> <span class="nav-text">SortShuffleWriter</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ExternalSorter"><span class="nav-number">4.2.</span> <span class="nav-text">ExternalSorter</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE-1"><span class="nav-number">4.2.1.</span> <span class="nav-text">写入数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%BA%A2%E5%87%BA-1"><span class="nav-number">4.2.2.</span> <span class="nav-text">溢出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%88%E5%B9%B6%E6%96%87%E4%BB%B6-1"><span class="nav-number">4.2.3.</span> <span class="nav-text">合并文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SpillableIterator"><span class="nav-number">4.3.</span> <span class="nav-text">SpillableIterator</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SpillReader"><span class="nav-number">4.4.</span> <span class="nav-text">SpillReader</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#WritablePartitionedPairCollection"><span class="nav-number">4.5.</span> <span class="nav-text">WritablePartitionedPairCollection</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%A5%E5%85%B7%E6%96%B9%E6%B3%95"><span class="nav-number">4.5.1.</span> <span class="nav-text">工具方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PartitionedAppendOnlyMap"><span class="nav-number">4.6.</span> <span class="nav-text">PartitionedAppendOnlyMap</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PartitionedPairBuffer"><span class="nav-number">4.7.</span> <span class="nav-text">PartitionedPairBuffer</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#NOTEs"><span class="nav-number">5.</span> <span class="nav-text">NOTEs</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">JT Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">68</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="mailto:jtli.brain@hotmail.com" title="E-Mail → mailto:jtli.brain@hotmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jtlibrain.github.io/2020/08/05/spark/Spark-shuffle-writer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="JT Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="jtLiBrain">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark shuffle writer
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-08-05 16:37:46" itemprop="dateCreated datePublished" datetime="2020-08-05T16:37:46+08:00">2020-08-05</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-11-29 12:51:07" itemprop="dateModified" datetime="2020-11-29T12:51:07+08:00">2020-11-29</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/spark/" itemprop="url" rel="index"><span itemprop="name">spark</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>本篇介绍ShuffleWriter的原理。shuffle任务的运行，请参看<a href="/2020/08/28/Spark-run-task-details/#ShuffleMapTask">此文章</a>。</p>
<a id="more"></a>

<h1 id="DiskBlockObjectWriter"><a href="#DiskBlockObjectWriter" class="headerlink" title="DiskBlockObjectWriter"></a>DiskBlockObjectWriter</h1><p>我们首先来看一下DiskBlockObjectWriter，接下来要介绍的三种ShuffleWriter都使用了这个类，DiskBlockObjectWriter类将Java对象直接写入到磁盘上的文件，它封装并包装了文件流。</p>
<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">initialize</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">  fos = <span class="keyword">new</span> <span class="type">FileOutputStream</span>(file, <span class="literal">true</span>)</span><br><span class="line">  channel = fos.getChannel()</span><br><span class="line">  ts = <span class="keyword">new</span> <span class="type">TimeTrackingOutputStream</span>(writeMetrics, fos)</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">ManualCloseBufferedOutputStream</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">BufferedOutputStream</span>(<span class="params">ts, bufferSize</span>) <span class="keyword">with</span> <span class="title">ManualCloseOutputStream</span></span></span><br><span class="line"><span class="class">  <span class="title">mcs</span> </span>= <span class="keyword">new</span> <span class="type">ManualCloseBufferedOutputStream</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

  <br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open</span></span>(): <span class="type">DiskBlockObjectWriter</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (hasBeenClosed) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;Writer already closed. Cannot be reopened.&quot;</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!initialized) &#123;</span><br><span class="line">    initialize()</span><br><span class="line">    initialized = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  bs = serializerManager.wrapStream(blockId, mcs) <span class="comment">// 对文件流进行压缩和加密</span></span><br><span class="line">  objOut = serializerInstance.serializeStream(bs) <span class="comment">// 对文件流进行序列化</span></span><br><span class="line">  streamOpen = <span class="literal">true</span></span><br><span class="line">  <span class="keyword">this</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

   <br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 压缩格式由spark.io.compression.codec进行配置</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">shouldCompress</span></span>(blockId: <span class="type">BlockId</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  blockId <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> _: <span class="type">ShuffleBlockId</span> =&gt; compressShuffle <span class="comment">// spark.shuffle.compress</span></span><br><span class="line">    <span class="keyword">case</span> _: <span class="type">BroadcastBlockId</span> =&gt; compressBroadcast <span class="comment">//spark.broadcast.compress</span></span><br><span class="line">    <span class="keyword">case</span> _: <span class="type">RDDBlockId</span> =&gt; compressRdds <span class="comment">// spark.rdd.compress</span></span><br><span class="line">    <span class="keyword">case</span> _: <span class="type">TempLocalBlockId</span> =&gt; compressShuffleSpill <span class="comment">// spark.shuffle.spill.compress</span></span><br><span class="line">    <span class="keyword">case</span> _: <span class="type">TempShuffleBlockId</span> =&gt; compressShuffle <span class="comment">// spark.shuffle.compress</span></span><br><span class="line">    <span class="keyword">case</span> _ =&gt; <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 该方法将KV对以java对象的形式进行写入，</span></span><br><span class="line"><span class="comment">// 注意，该方法使用了objOut写入，它包装了序列化和压缩的逻辑</span></span><br><span class="line"><span class="comment">// BypassMergeSortShuffleWriter和SortShuffleWriter使用了这个方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(key: <span class="type">Any</span>, value: <span class="type">Any</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (!streamOpen) &#123;</span><br><span class="line">    open()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  objOut.writeKey(key)</span><br><span class="line">  objOut.writeValue(value)</span><br><span class="line">  recordWritten()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 该方法直接将字节数组写入流，</span></span><br><span class="line"><span class="comment">// 注意，该方法使用了bs写入，它包装只有压缩的逻辑，不进行序列化，</span></span><br><span class="line"><span class="comment">// UnsafeShuffleWriter使用了这个方法</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(kvBytes: <span class="type">Array</span>[<span class="type">Byte</span>], offs: <span class="type">Int</span>, len: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (!streamOpen) &#123;</span><br><span class="line">    open()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  bs.write(kvBytes, offs, len)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="BypassMergeSortShuffleWriter原理"><a href="#BypassMergeSortShuffleWriter原理" class="headerlink" title="BypassMergeSortShuffleWriter原理"></a>BypassMergeSortShuffleWriter原理</h1><p>BypassMergeSortShuffleWriter不利用Spark执行缓存，根据输入记录的key，将其直接写入到单独文件，每个文件对应一个reduce分区，最后将这些文件按照分区ID依序拼接起来形成最终的输出文件。</p>
<p>优点：由序列化写入的临时shuffle文件拼接最终文件的时候，不需要解序列化，直接按字节流copy数据，性能比较高。</p>
<p>缺点：这个ShuffleWriter在有大量reduce分区时，性能不高，因为它会为所有reduce分区同时打开序列化器和文件流。</p>
<p><img src="/images/spark/BypassMergeSortShuffleWriter.svg"></p>
  <br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">public void write(<span class="type">Iterator</span>&lt;<span class="type">Product2</span>&lt;<span class="type">K</span>, <span class="type">V</span>&gt;&gt; records) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  assert (partitionWriters == <span class="literal">null</span>);</span><br><span class="line">  <span class="keyword">if</span> (!records.hasNext()) &#123;</span><br><span class="line">    partitionLengths = <span class="keyword">new</span> long[numPartitions];</span><br><span class="line">    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, <span class="literal">null</span>);</span><br><span class="line">    mapStatus = <span class="type">MapStatus</span>$.<span class="type">MODULE</span>$.apply(blockManager.shuffleServerId(), partitionLengths);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">final</span> <span class="type">SerializerInstance</span> serInstance = serializer.newInstance();</span><br><span class="line">  <span class="keyword">final</span> long openStartTime = <span class="type">System</span>.nanoTime();</span><br><span class="line">  partitionWriters = <span class="keyword">new</span> <span class="type">DiskBlockObjectWriter</span>[numPartitions];</span><br><span class="line">  partitionWriterSegments = <span class="keyword">new</span> <span class="type">FileSegment</span>[numPartitions];</span><br><span class="line">  <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; numPartitions; i++) &#123;</span><br><span class="line">    <span class="comment">// 为每个分区分别创建临时分区文件和shuffle block</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Tuple2</span>&lt;<span class="type">TempShuffleBlockId</span>, <span class="type">File</span>&gt; tempShuffleBlockIdPlusFile =</span><br><span class="line">      blockManager.diskBlockManager().createTempShuffleBlock();</span><br><span class="line">    <span class="keyword">final</span> <span class="type">File</span> file = tempShuffleBlockIdPlusFile._2();</span><br><span class="line">    <span class="keyword">final</span> <span class="type">BlockId</span> blockId = tempShuffleBlockIdPlusFile._1();</span><br><span class="line">    <span class="comment">// 每个分区创建一个写入器</span></span><br><span class="line">    partitionWriters[i] =</span><br><span class="line">      blockManager.getDiskWriter(blockId, file, serInstance, fileBufferSize, writeMetrics);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Creating the file to write to and creating a disk writer both involve interacting with</span></span><br><span class="line">  <span class="comment">// the disk, and can take a long time in aggregate when we open many files, so should be</span></span><br><span class="line">  <span class="comment">// included in the shuffle write time.</span></span><br><span class="line">  writeMetrics.incWriteTime(<span class="type">System</span>.nanoTime() - openStartTime);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (records.hasNext()) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">Product2</span>&lt;<span class="type">K</span>, <span class="type">V</span>&gt; record = records.next();</span><br><span class="line">    <span class="keyword">final</span> <span class="type">K</span> key = record._1();</span><br><span class="line">    <span class="comment">// 根据record的key，将其写入相应的分区文件中</span></span><br><span class="line">    partitionWriters[partitioner.getPartition(key)].write(key, record._2());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 写入完成，调用commitAndGet()和close()</span></span><br><span class="line">  <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; numPartitions; i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">DiskBlockObjectWriter</span> writer = partitionWriters[i];</span><br><span class="line">    partitionWriterSegments[i] = writer.commitAndGet();</span><br><span class="line">    writer.close();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">File</span> output = shuffleBlockResolver.getDataFile(shuffleId, mapId);</span><br><span class="line">  <span class="type">File</span> tmp = <span class="type">Utils</span>.tempFileWith(output);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 将临时文件拼接成一个最终的文件</span></span><br><span class="line">    partitionLengths = writePartitionedFile(tmp);</span><br><span class="line">    <span class="comment">// 写入索引文件</span></span><br><span class="line">    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, tmp);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (tmp.exists() &amp;&amp; !tmp.delete()) &#123;</span><br><span class="line">      logger.error(<span class="string">&quot;Error while deleting temp file &#123;&#125;&quot;</span>, tmp.getAbsolutePath());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  mapStatus = <span class="type">MapStatus</span>$.<span class="type">MODULE</span>$.apply(blockManager.shuffleServerId(), partitionLengths);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

  <br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将分区文件拼接成一个汇总文件</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @return 返回一个数值数组，其中数值项代表每个分区数据的字节长度</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> long[] writePartitionedFile(<span class="type">File</span> outputFile) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  <span class="comment">// Track location of the partition starts in the output file</span></span><br><span class="line">  <span class="keyword">final</span> long[] lengths = <span class="keyword">new</span> long[numPartitions];</span><br><span class="line">  <span class="keyword">if</span> (partitionWriters == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="comment">// We were passed an empty iterator</span></span><br><span class="line">    <span class="keyword">return</span> lengths;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="type">FileOutputStream</span> out = <span class="keyword">new</span> <span class="type">FileOutputStream</span>(outputFile, <span class="literal">true</span>);</span><br><span class="line">  <span class="keyword">final</span> long writeStartTime = <span class="type">System</span>.nanoTime();</span><br><span class="line">  boolean threwException = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; numPartitions; i++) &#123; <span class="comment">// 按分区ID，将分区文件数据copy到最终的文件</span></span><br><span class="line">      <span class="keyword">final</span> <span class="type">File</span> file = partitionWriterSegments[i].file();</span><br><span class="line">      <span class="keyword">if</span> (file.exists()) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">FileInputStream</span> in = <span class="keyword">new</span> <span class="type">FileInputStream</span>(file);</span><br><span class="line">        boolean copyThrewException = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          lengths[i] = <span class="type">Utils</span>.copyStream(in, out, <span class="literal">false</span>, transferToEnabled);</span><br><span class="line">          copyThrewException = <span class="literal">false</span>;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          <span class="type">Closeables</span>.close(in, copyThrewException);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!file.delete()) &#123;</span><br><span class="line">          logger.error(<span class="string">&quot;Unable to delete file for partition &#123;&#125;&quot;</span>, i);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    threwException = <span class="literal">false</span>;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="type">Closeables</span>.close(out, threwException);</span><br><span class="line">    writeMetrics.incWriteTime(<span class="type">System</span>.nanoTime() - writeStartTime);</span><br><span class="line">  &#125;</span><br><span class="line">  partitionWriters = <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">return</span> lengths;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="UnsafeShuffleWriter原理"><a href="#UnsafeShuffleWriter原理" class="headerlink" title="UnsafeShuffleWriter原理"></a>UnsafeShuffleWriter原理</h1><p><img src="/images/spark/UnsafeShuffleWriter.svg"></p>
<p>该类底层使用了 sun.misc.Unsafe，顾名思义叫UnsafeShuffleWriter。</p>
<p>在内部，它将数据序列化后提交给ShuffleExternalSorter，ShuffleExternalSorter将数据写入到内存分页当中，并同时将该数据在内存对应的地址信息（内存分页编号+内存的offset）和相应的分区ID进行编码作为数据指针插入到基于内存排序的ShuffleInMemorySorter中。</p>
<p>当发生溢出时，通过ShuffleInMemorySorter基于对数据指针进行排序（只对数据指针的分区ID进行排序）从而达到对内存分页中数据排序的效果，并最终将排序数据按分区ID的顺序依次输出到临时溢出文件中。在通过DiskBlockObjectWriter写入文件时，每个分区进行一次提交，每次提交记录一个FileSegment。</p>
<p>ShuffleExternalSorter会将最后的内存分页也写入到磁盘文件，合并阶段是完全基于这些溢出文件进行的。合并时，针对是否支持快速合并的要求，执行快合并或慢合并（快合并的条件是：a)不开启压缩，或 b)如果开启了压缩，Snappy、LZF、LZ4、ZStd支持快合并）。其中慢合并会涉及到对溢出文件流进行解序列化的操作，合并后再序列化输出到最终shuffle文件，开销比较大。</p>
<p>下图描绘了UnsafeShuffleWriter的实现细节：</p>
<p><img src="/images/spark/UnsafeShuffleWriter-details.svg"></p>
<h2 id="TaskMemoryManager"><a href="#TaskMemoryManager" class="headerlink" title="TaskMemoryManager"></a>TaskMemoryManager</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 分页表，每个MemoryBlock都有pageNumber属性，其属性值对应相应该MemoryBlock在此分页表的索引位置</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">MemoryBlock</span>[] pageTable = <span class="keyword">new</span> <span class="type">MemoryBlock</span>[<span class="type">PAGE_TABLE_SIZE</span>];</span><br></pre></td></tr></table></figure>

<h2 id="UnsafeShuffleWriter"><a href="#UnsafeShuffleWriter" class="headerlink" title="UnsafeShuffleWriter"></a>UnsafeShuffleWriter</h2><h3 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//写入当前分区的数据</span></span><br><span class="line">public void write(scala.collection.<span class="type">Iterator</span>&lt;<span class="type">Product2</span>&lt;<span class="type">K</span>, <span class="type">V</span>&gt;&gt; records) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  <span class="comment">// Keep track of success so we know if we encountered an exception</span></span><br><span class="line">  <span class="comment">// We do this rather than a standard try/catch/re-throw to handle</span></span><br><span class="line">  <span class="comment">// generic throwables.</span></span><br><span class="line">  boolean success = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (records.hasNext()) &#123;</span><br><span class="line">      insertRecordIntoSorter(records.next());</span><br><span class="line">    &#125;</span><br><span class="line">    closeAndWriteOutput();</span><br><span class="line">    success = <span class="literal">true</span>;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<p>MyByteArrayOutputStream扩展自ByteArrayOutputStream，是一个内存字节流；SerializationStream包装了MyByteArrayOutputStream，将record序列化后结果存入底层的MyByteArrayOutputStream；ByteArrayOutputStream公布了getBuf() ，这样就可以获取到底层序列化后的字节数据了。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">void insertRecordIntoSorter(<span class="type">Product2</span>&lt;<span class="type">K</span>, <span class="type">V</span>&gt; record) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  assert(sorter != <span class="literal">null</span>);</span><br><span class="line">  <span class="keyword">final</span> <span class="type">K</span> key = record._1();</span><br><span class="line">  <span class="keyword">final</span> int partitionId = partitioner.getPartition(key);</span><br><span class="line">  serBuffer.reset();</span><br><span class="line">  serOutputStream.writeKey(key, <span class="type">OBJECT_CLASS_TAG</span>);</span><br><span class="line">  serOutputStream.writeValue(record._2(), <span class="type">OBJECT_CLASS_TAG</span>); <span class="comment">// 序列化</span></span><br><span class="line">  serOutputStream.flush();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> int serializedRecordSize = serBuffer.size();</span><br><span class="line">  assert (serializedRecordSize &gt; <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  sorter.insertRecord(</span><br><span class="line">    serBuffer.getBuf(), <span class="type">Platform</span>.<span class="type">BYTE_ARRAY_OFFSET</span>, serializedRecordSize, partitionId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="合并文件"><a href="#合并文件" class="headerlink" title="合并文件"></a>合并文件</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">void closeAndWriteOutput() <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  assert(sorter != <span class="literal">null</span>);</span><br><span class="line">  updatePeakMemoryUsed();</span><br><span class="line">  serBuffer = <span class="literal">null</span>;</span><br><span class="line">  serOutputStream = <span class="literal">null</span>;</span><br><span class="line">  <span class="comment">// 将全部的内存分页写入到磁盘，并释放相应内存</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">SpillInfo</span>[] spills = sorter.closeAndGetSpills();</span><br><span class="line">  sorter = <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">final</span> long[] partitionLengths;</span><br><span class="line">  <span class="keyword">final</span> <span class="type">File</span> output = shuffleBlockResolver.getDataFile(shuffleId, mapId);</span><br><span class="line">  <span class="keyword">final</span> <span class="type">File</span> tmp = <span class="type">Utils</span>.tempFileWith(output);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      partitionLengths = mergeSpills(spills, tmp);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">SpillInfo</span> spill : spills) &#123;</span><br><span class="line">        <span class="keyword">if</span> (spill.file.exists() &amp;&amp; ! spill.file.delete()) &#123;</span><br><span class="line">          logger.error(<span class="string">&quot;Error while deleting spill file &#123;&#125;&quot;</span>, spill.file.getPath());</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, tmp);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (tmp.exists() &amp;&amp; !tmp.delete()) &#123;</span><br><span class="line">      logger.error(<span class="string">&quot;Error while deleting temp file &#123;&#125;&quot;</span>, tmp.getAbsolutePath());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  mapStatus = <span class="type">MapStatus</span>$.<span class="type">MODULE</span>$.apply(blockManager.shuffleServerId(), partitionLengths);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> long[] mergeSpills(<span class="type">SpillInfo</span>[] spills, <span class="type">File</span> outputFile) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  <span class="keyword">final</span> boolean compressionEnabled = sparkConf.getBoolean(<span class="string">&quot;spark.shuffle.compress&quot;</span>, <span class="literal">true</span>);</span><br><span class="line">  <span class="keyword">final</span> <span class="type">CompressionCodec</span> compressionCodec = <span class="type">CompressionCodec</span>$.<span class="type">MODULE</span>$.createCodec(sparkConf);</span><br><span class="line">  <span class="keyword">final</span> boolean fastMergeEnabled =</span><br><span class="line">    sparkConf.getBoolean(<span class="string">&quot;spark.shuffle.unsafe.fastMergeEnabled&quot;</span>, <span class="literal">true</span>);</span><br><span class="line">  <span class="comment">// 非压缩或Snappy、LZF、LZ4、ZStd都支持快速合并</span></span><br><span class="line">  <span class="keyword">final</span> boolean fastMergeIsSupported = !compressionEnabled ||</span><br><span class="line">    <span class="type">CompressionCodec</span>$.<span class="type">MODULE</span>$.supportsConcatenationOfSerializedStreams(compressionCodec);</span><br><span class="line">  <span class="keyword">final</span> boolean encryptionEnabled = blockManager.serializerManager().encryptionEnabled();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (spills.length == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">new</span> <span class="type">FileOutputStream</span>(outputFile).close(); <span class="comment">// Create an empty file</span></span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> long[partitioner.numPartitions()];</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (spills.length == <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="comment">// Here, we don&#x27;t need to perform any metrics updates because the bytes written to this</span></span><br><span class="line">      <span class="comment">// output file would have already been counted as shuffle bytes written.</span></span><br><span class="line">      <span class="type">Files</span>.move(spills[<span class="number">0</span>].file, outputFile);</span><br><span class="line">      <span class="keyword">return</span> spills[<span class="number">0</span>].partitionLengths;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">final</span> long[] partitionLengths;</span><br><span class="line">            </span><br><span class="line">      <span class="comment">// 快速合并的前提是：</span></span><br><span class="line">      <span class="comment">// 1. 不开启压缩；</span></span><br><span class="line">      <span class="comment">// 2. 如果开启了压缩，Snappy、LZF、LZ4、ZStd是可以进行在不解压缩情况下，执行数据拼接</span></span><br><span class="line">      <span class="keyword">if</span> (fastMergeEnabled &amp;&amp; fastMergeIsSupported) &#123;</span><br><span class="line">        <span class="keyword">if</span> (transferToEnabled &amp;&amp; !encryptionEnabled) &#123;</span><br><span class="line">          logger.debug(<span class="string">&quot;Using transferTo-based fast merge&quot;</span>);</span><br><span class="line">          <span class="comment">// 使用NIO进行快速合并</span></span><br><span class="line">          partitionLengths = mergeSpillsWithTransferTo(spills, outputFile);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          logger.debug(<span class="string">&quot;Using fileStream-based fast merge&quot;</span>);</span><br><span class="line">          <span class="comment">// 使用java文件流进行合并，往往会比mergeSpillsWithTransferTo()要慢</span></span><br><span class="line">          partitionLengths = mergeSpillsWithFileStream(spills, outputFile, <span class="literal">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        logger.debug(<span class="string">&quot;Using slow merge&quot;</span>);</span><br><span class="line">        <span class="comment">// 解压缩溢出文件流，再对输出流进行压缩，性能很差</span></span><br><span class="line">        partitionLengths = mergeSpillsWithFileStream(spills, outputFile, compressionCodec);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      writeMetrics.decBytesWritten(spills[spills.length - <span class="number">1</span>].file.length());</span><br><span class="line">      writeMetrics.incBytesWritten(outputFile.length());</span><br><span class="line">      <span class="keyword">return</span> partitionLengths;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (<span class="type">IOException</span> e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (outputFile.exists() &amp;&amp; !outputFile.delete()) &#123;</span><br><span class="line">      logger.error(<span class="string">&quot;Unable to delete output file &#123;&#125;&quot;</span>, outputFile.getPath());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="ShuffleExternalSorter"><a href="#ShuffleExternalSorter" class="headerlink" title="ShuffleExternalSorter"></a>ShuffleExternalSorter</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 排序的内存分页，这些分页的内存已经被释放并且其内的数据已经被溢出到磁盘</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">LinkedList</span>&lt;<span class="type">MemoryBlock</span>&gt; allocatedPages = <span class="keyword">new</span> <span class="type">LinkedList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 每次溢出由一个SpillInfo来表示，其内有溢出文件的统计信息</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">LinkedList</span>&lt;<span class="type">SpillInfo</span>&gt; spills = <span class="keyword">new</span> <span class="type">LinkedList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 当前数据分页的排序器，每次溢出后，进行重置inMemSorter.reset()</span></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> <span class="type">ShuffleInMemorySorter</span> inMemSorter;</span><br><span class="line"><span class="comment">// 当前数据分页，每次溢出后，置空currentPage=null</span></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> <span class="type">MemoryBlock</span> currentPage = <span class="literal">null</span>;</span><br><span class="line"><span class="comment">// 当前数据分页中的offset，每次溢出后，pageCursor=0</span></span><br><span class="line"><span class="keyword">private</span> long pageCursor = <span class="number">-1</span>;</span><br></pre></td></tr></table></figure>



<h3 id="插入record数据"><a href="#插入record数据" class="headerlink" title="插入record数据"></a>插入record数据</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">public void insertRecord(<span class="type">Object</span> recordBase, long recordOffset, int length, int partitionId)</span><br><span class="line">  <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// for tests</span></span><br><span class="line">  assert(inMemSorter != <span class="literal">null</span>);</span><br><span class="line">  <span class="keyword">if</span> (inMemSorter.numRecords() &gt;= numElementsForSpillThreshold) &#123;</span><br><span class="line">    logger.info(<span class="string">&quot;Spilling data because number of spilledRecords crossed the threshold &quot;</span> +</span><br><span class="line">      numElementsForSpillThreshold);</span><br><span class="line">    spill();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  growPointerArrayIfNecessary();</span><br><span class="line">  <span class="keyword">final</span> int uaoSize = <span class="type">UnsafeAlignedOffset</span>.getUaoSize();</span><br><span class="line">  <span class="comment">// Need 4 or 8 bytes to store the record length.</span></span><br><span class="line">  <span class="keyword">final</span> int required = length + uaoSize;</span><br><span class="line">  acquireNewPageIfNecessary(required);</span><br><span class="line"></span><br><span class="line">  assert(currentPage != <span class="literal">null</span>);</span><br><span class="line">  <span class="keyword">final</span> <span class="type">Object</span> base = currentPage.getBaseObject();</span><br><span class="line">  <span class="comment">// 对当前内存分页和pageCursor进行编码，作为当前写入数据的地址</span></span><br><span class="line">  <span class="comment">// 注意，该地址，高13位表示内存分页，低51为表示当前页的偏移量</span></span><br><span class="line">  <span class="keyword">final</span> long recordAddress = taskMemoryManager.encodePageNumberAndOffset(currentPage, pageCursor);</span><br><span class="line">  <span class="type">UnsafeAlignedOffset</span>.putSize(base, pageCursor, length);</span><br><span class="line">  pageCursor += uaoSize;</span><br><span class="line">  <span class="comment">// 1. 从序列化数据recordBase的recordOffset处，到base的pageCursor处，copy数据，长度为length，</span></span><br><span class="line">  <span class="comment">//    注意这里数据页中留出了uaoSize对齐的空间</span></span><br><span class="line">  <span class="type">Platform</span>.copyMemory(recordBase, recordOffset, base, pageCursor, length);</span><br><span class="line">  pageCursor += length;</span><br><span class="line">  <span class="comment">// 2. 向inMemSorter插入指针记录，用于排序</span></span><br><span class="line">  inMemSorter.insertRecord(recordAddress, partitionId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="溢出"><a href="#溢出" class="headerlink" title="溢出"></a>溢出</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Sort and spill the current records in response to memory pressure.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">public long spill(long size, <span class="type">MemoryConsumer</span> trigger) <span class="keyword">throws</span> <span class="type">IOException</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (trigger != <span class="keyword">this</span> || inMemSorter == <span class="literal">null</span> || inMemSorter.numRecords() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>L;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  logger.info(<span class="string">&quot;Thread &#123;&#125; spilling sort data of &#123;&#125; to disk (&#123;&#125; &#123;&#125; so far)&quot;</span>,</span><br><span class="line">    <span class="type">Thread</span>.currentThread().getId(),</span><br><span class="line">    <span class="type">Utils</span>.bytesToString(getMemoryUsage()),</span><br><span class="line">    spills.size(),</span><br><span class="line">    spills.size() &gt; <span class="number">1</span> ? <span class="string">&quot; times&quot;</span> : <span class="string">&quot; time&quot;</span>);</span><br><span class="line"></span><br><span class="line">  writeSortedFile(<span class="literal">false</span>);</span><br><span class="line">  <span class="keyword">final</span> long spillSize = freeMemory();</span><br><span class="line">  inMemSorter.reset();</span><br><span class="line">  <span class="comment">// Reset the in-memory sorter&#x27;s pointer array only after freeing up the memory pages holding the</span></span><br><span class="line">  <span class="comment">// records. Otherwise, if the task is over allocated memory, then without freeing the memory</span></span><br><span class="line">  <span class="comment">// pages, we might not be able to get memory for the pointer array.</span></span><br><span class="line">  taskContext.taskMetrics().incMemoryBytesSpilled(spillSize);</span><br><span class="line">  <span class="keyword">return</span> spillSize;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对内存中的记录进行排序，然后将排序后的记录写入到磁盘上的文件</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> void writeSortedFile(boolean isLastFile) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="type">ShuffleWriteMetrics</span> writeMetricsToUse;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (isLastFile) &#123;</span><br><span class="line">    <span class="comment">// We&#x27;re writing the final non-spill file, so we _do_ want to count this as shuffle bytes.</span></span><br><span class="line">    writeMetricsToUse = writeMetrics;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// We&#x27;re spilling, so bytes written should be counted towards spill rather than write.</span></span><br><span class="line">    <span class="comment">// Create a dummy WriteMetrics object to absorb these metrics, since we don&#x27;t want to count</span></span><br><span class="line">    <span class="comment">// them towards shuffle bytes written.</span></span><br><span class="line">    writeMetricsToUse = <span class="keyword">new</span> <span class="type">ShuffleWriteMetrics</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对当前数据分页对应的指针数组进行排序</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">ShuffleInMemorySorter</span>.<span class="type">ShuffleSorterIterator</span> sortedRecords =</span><br><span class="line">    inMemSorter.getSortedIterator();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 小数据量写入到DiskBlockObjectWriter性能是极其不高效的，这里使用字节数组充当缓存</span></span><br><span class="line">  <span class="keyword">final</span> byte[] writeBuffer = <span class="keyword">new</span> byte[diskWriteBufferSize];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Because this output will be read during shuffle, its compression codec must be controlled by</span></span><br><span class="line">  <span class="comment">// spark.shuffle.compress instead of spark.shuffle.spill.compress, so we need to use</span></span><br><span class="line">  <span class="comment">// createTempShuffleBlock here; see SPARK-3426 for more details.</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Tuple2</span>&lt;<span class="type">TempShuffleBlockId</span>, <span class="type">File</span>&gt; spilledFileInfo =</span><br><span class="line">    blockManager.diskBlockManager().createTempShuffleBlock();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">File</span> file = spilledFileInfo._2();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">TempShuffleBlockId</span> blockId = spilledFileInfo._1();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">SpillInfo</span> spillInfo = <span class="keyword">new</span> <span class="type">SpillInfo</span>(numPartitions, file, blockId);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 我们需要一个serializer实例来构造DiskBlockObjectWriter对象，DiskBlockObjectWriter对象封装并包装了文件流，</span></span><br><span class="line">  <span class="comment">// 但UnsafeShuffleWriter实际上并没有使用这个serializer，因为下面写入文件时调用的是</span></span><br><span class="line">  <span class="comment">// DiskBlockObjectWriter.write(kvBytes: Array[Byte], offs: Int, len: Int)，</span></span><br><span class="line">  <span class="comment">// 这个方法实际直接将字节数据写入包装后的压缩流，并没有使用序列化流，因为数据分页中的数据已经是经过序列化后的数据了,</span></span><br><span class="line">  <span class="comment">// 所以，这里传递了一个虚设的没有实际作用的serializer。</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">SerializerInstance</span> ser = <span class="type">DummySerializerInstance</span>.<span class="type">INSTANCE</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="type">DiskBlockObjectWriter</span> writer =</span><br><span class="line">    blockManager.getDiskWriter(blockId, file, ser, fileBufferSizeBytes, writeMetricsToUse);</span><br><span class="line"></span><br><span class="line">  int currentPartition = <span class="number">-1</span>;</span><br><span class="line">  <span class="keyword">final</span> int uaoSize = <span class="type">UnsafeAlignedOffset</span>.getUaoSize();</span><br><span class="line">  <span class="keyword">while</span> (sortedRecords.hasNext()) &#123;</span><br><span class="line">    sortedRecords.loadNext();</span><br><span class="line">    <span class="keyword">final</span> int partition = sortedRecords.packedRecordPointer.getPartitionId();</span><br><span class="line">    assert (partition &gt;= currentPartition);</span><br><span class="line">    <span class="keyword">if</span> (partition != currentPartition) &#123;</span><br><span class="line">      <span class="comment">// Switch to the new partition</span></span><br><span class="line">      <span class="keyword">if</span> (currentPartition != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">FileSegment</span> fileSegment = writer.commitAndGet(); <span class="comment">// 每个分区对应一个文件分片</span></span><br><span class="line">        spillInfo.partitionLengths[currentPartition] = fileSegment.length();</span><br><span class="line">      &#125;</span><br><span class="line">      currentPartition = partition;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> long recordPointer = sortedRecords.packedRecordPointer.getRecordPointer();</span><br><span class="line">    <span class="keyword">final</span> <span class="type">Object</span> recordPage = taskMemoryManager.getPage(recordPointer);</span><br><span class="line">    <span class="keyword">final</span> long recordOffsetInPage = taskMemoryManager.getOffsetInPage(recordPointer);</span><br><span class="line">    int dataRemaining = <span class="type">UnsafeAlignedOffset</span>.getSize(recordPage, recordOffsetInPage);</span><br><span class="line">    long recordReadPosition = recordOffsetInPage + uaoSize; <span class="comment">// skip over record length</span></span><br><span class="line">    <span class="keyword">while</span> (dataRemaining &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">final</span> int toTransfer = <span class="type">Math</span>.min(diskWriteBufferSize, dataRemaining);</span><br><span class="line">      <span class="comment">// 将数据从数据分页中copy到数组缓存</span></span><br><span class="line">      <span class="type">Platform</span>.copyMemory(</span><br><span class="line">        recordPage, recordReadPosition, writeBuffer, <span class="type">Platform</span>.<span class="type">BYTE_ARRAY_OFFSET</span>, toTransfer);</span><br><span class="line">      <span class="comment">// 将数组缓存中的数据写入</span></span><br><span class="line">      writer.write(writeBuffer, <span class="number">0</span>, toTransfer);</span><br><span class="line">      recordReadPosition += toTransfer;</span><br><span class="line">      dataRemaining -= toTransfer;</span><br><span class="line">    &#125;</span><br><span class="line">    writer.recordWritten();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="type">FileSegment</span> committedSegment = writer.commitAndGet();</span><br><span class="line">  writer.close();</span><br><span class="line">  <span class="comment">// If `writeSortedFile()` was called from `closeAndGetSpills()` and no records were inserted,</span></span><br><span class="line">  <span class="comment">// then the file might be empty. Note that it might be better to avoid calling</span></span><br><span class="line">  <span class="comment">// writeSortedFile() in that case.</span></span><br><span class="line">  <span class="keyword">if</span> (currentPartition != <span class="number">-1</span>) &#123;</span><br><span class="line">    spillInfo.partitionLengths[currentPartition] = committedSegment.length();</span><br><span class="line">    spills.add(spillInfo);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!isLastFile) &#123;  <span class="comment">// i.e. this is a spill file</span></span><br><span class="line">    <span class="comment">// The current semantics of `shuffleRecordsWritten` seem to be that it&#x27;s updated when records</span></span><br><span class="line">    <span class="comment">// are written to disk, not when they enter the shuffle sorting code. DiskBlockObjectWriter</span></span><br><span class="line">    <span class="comment">// relies on its `recordWritten()` method being called in order to trigger periodic updates to</span></span><br><span class="line">    <span class="comment">// `shuffleBytesWritten`. If we were to remove the `recordWritten()` call and increment that</span></span><br><span class="line">    <span class="comment">// counter at a higher-level, then the in-progress metrics for records written and bytes</span></span><br><span class="line">    <span class="comment">// written would get out of sync.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// When writing the last file, we pass `writeMetrics` directly to the DiskBlockObjectWriter;</span></span><br><span class="line">    <span class="comment">// in all other cases, we pass in a dummy write metrics to capture metrics, then copy those</span></span><br><span class="line">    <span class="comment">// metrics to the true write metrics here. The reason for performing this copying is so that</span></span><br><span class="line">    <span class="comment">// we can avoid reporting spilled bytes as shuffle write bytes.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Note that we intentionally ignore the value of `writeMetricsToUse.shuffleWriteTime()`.</span></span><br><span class="line">    <span class="comment">// Consistent with ExternalSorter, we do not count this IO towards shuffle write time.</span></span><br><span class="line">    <span class="comment">// This means that this IO time is not accounted for anywhere; SPARK-3577 will fix this.</span></span><br><span class="line">    writeMetrics.incRecordsWritten(writeMetricsToUse.recordsWritten());</span><br><span class="line">    taskContext.taskMetrics().incDiskBytesSpilled(writeMetricsToUse.bytesWritten());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="ShuffleInMemorySorter"><a href="#ShuffleInMemorySorter" class="headerlink" title="ShuffleInMemorySorter"></a>ShuffleInMemorySorter</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 指针数组，</span></span><br><span class="line"><span class="comment"> * 1. 其中指针为：记录地址+分区ID经过PackedRecordPointer压缩后的指针；</span></span><br><span class="line"><span class="comment"> * 2. 排序操作实际是在该数组上进行的，而不是直接对底层数据进行排序；</span></span><br><span class="line"><span class="comment"> * 3. 该数据中只有一部分用于存储指针，剩余空间用作排序时的缓存；</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">LongArray</span> array;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 指针数组中新纪录插入的位置，每插入一条新记录，该指针递增1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> int pos = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>

<h3 id="插入记录指针"><a href="#插入记录指针" class="headerlink" title="插入记录指针"></a>插入记录指针</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public void insertRecord(long recordPointer, int partitionId) &#123;</span><br><span class="line">  <span class="keyword">if</span> (!hasSpaceForAnotherRecord()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;There is no space for new record&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  array.set(pos, <span class="type">PackedRecordPointer</span>.packPointer(recordPointer, partitionId));</span><br><span class="line">  pos++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>PackedRecordPointer.packPointer()压缩后的指针结构为：</p>
<p><img src="/images/spark/ShuffleInMemorySorter-packPointer.svg"></p>
<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对记录指针数组进行排序，并返回相应迭代器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">public <span class="type">ShuffleSorterIterator</span> getSortedIterator() &#123;</span><br><span class="line">  int offset = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (useRadixSort) &#123;</span><br><span class="line">    offset = <span class="type">RadixSort</span>.sort(</span><br><span class="line">      array, pos,</span><br><span class="line">      <span class="type">PackedRecordPointer</span>.<span class="type">PARTITION_ID_START_BYTE_INDEX</span>,</span><br><span class="line">      <span class="type">PackedRecordPointer</span>.<span class="type">PARTITION_ID_END_BYTE_INDEX</span>, <span class="literal">false</span>, <span class="literal">false</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">MemoryBlock</span> unused = <span class="keyword">new</span> <span class="type">MemoryBlock</span>(</span><br><span class="line">      array.getBaseObject(),</span><br><span class="line">      array.getBaseOffset() + pos * <span class="number">8</span>L,</span><br><span class="line">      (array.size() - pos) * <span class="number">8</span>L);</span><br><span class="line">    <span class="type">LongArray</span> buffer = <span class="keyword">new</span> <span class="type">LongArray</span>(unused);</span><br><span class="line">    <span class="type">Sorter</span>&lt;<span class="type">PackedRecordPointer</span>, <span class="type">LongArray</span>&gt; sorter =</span><br><span class="line">      <span class="keyword">new</span> <span class="type">Sorter</span>&lt;&gt;(<span class="keyword">new</span> <span class="type">ShuffleSortDataFormat</span>(buffer));</span><br><span class="line"></span><br><span class="line">    sorter.sort(array, <span class="number">0</span>, pos, <span class="type">SORT_COMPARATOR</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">ShuffleSorterIterator</span>(pos, array, offset);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<p>getSortedIterator()中在不开启基数排序(RadixSort)时使用的SortComparator：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> static <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">SortComparator</span> <span class="title">implements</span> <span class="title">Comparator&lt;PackedRecordPointer&gt;</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  public int compare(<span class="type">PackedRecordPointer</span> left, <span class="type">PackedRecordPointer</span> right) &#123;</span><br><span class="line">    int leftId = left.getPartitionId();</span><br><span class="line">    int rightId = right.getPartitionId();</span><br><span class="line">    <span class="keyword">return</span> leftId &lt; rightId ? <span class="number">-1</span> : (leftId &gt; rightId ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span> static <span class="keyword">final</span> <span class="type">SortComparator</span> <span class="type">SORT_COMPARATOR</span> = <span class="keyword">new</span> <span class="type">SortComparator</span>();</span><br></pre></td></tr></table></figure>



<h1 id="SortShuffleWriter原理"><a href="#SortShuffleWriter原理" class="headerlink" title="SortShuffleWriter原理"></a>SortShuffleWriter原理</h1><p><img src="/images/spark/SortShuffleWriter.svg"></p>
<p>在内部，它将数据提交给ExternalSorter，如果shuffle依赖需要进行map端合并，那么ExternalSorter将数据插入内存结构PartitionedAppendOnlyMap当中，否则将数据插入内存结构PartitionedPairBuffer。</p>
<p>当发生溢出时，ExternalSorter通过PartitionedAppendOnlyMap或PartitionedPairBuffer对内存集合进行排序并返回排序后数据的迭代器；排序时，首先比较数据的分区，分区ID作为第一排序依据，分区相同，分区内部中记录按record的“键”进行排序；如果shuffle操作是不排序/不聚合的操作，那么只按照分区ID进行排序。在写入溢出文件时，每个batch进行一次提交（由spark.shuffle.spill.batchSize控制，默认10000），每个batch对应一个文件分片（FileSegment），后面ExternalSorter在进行合并溢出文件的时候是以batch为单元进行读取文件的。最终溢出文件是序列化的、压缩的、排序的文件。</p>
<p>在合并溢出文件阶段，ExternalSorter根据是否同时存在溢出数据和内存数据，进行归并排序后输出到最终的shuffle文件中；其间，如果定义了聚合操作，归并后再进行聚合。归并排序的原理，参考<a href="/images/spark/ExternalSorter-mergeSort.svg">此图</a>。</p>
<p>缺点：该ShuffleWriter的不足之处是，在合并溢出文件的时候，会先解序列化文件流，归并排序后再把结果序列化输出到最终的文件中，序列化/解序列化的开销是其它ShuffleWriter的一倍。</p>
<p>下图描绘了SortShuffleWriter的实现细节：</p>
<p><img src="/images/spark/SortShuffleWriter-details.svg"></p>
<h2 id="SortShuffleWriter"><a href="#SortShuffleWriter" class="headerlink" title="SortShuffleWriter"></a>SortShuffleWriter</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">write</span></span>(records: <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  sorter = <span class="keyword">if</span> (dep.mapSideCombine) &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">ExternalSorter</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>](</span><br><span class="line">      context, dep.aggregator, <span class="type">Some</span>(dep.partitioner), dep.keyOrdering, dep.serializer)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 如果不需要map端合并，则aggregator和ordering都传None，</span></span><br><span class="line">    <span class="comment">// 因为不需要关心每个分区中key是否是排序的；</span></span><br><span class="line">    <span class="comment">// 如果运行的是sortByKey，那么key的排序在reduce端进行</span></span><br><span class="line">    <span class="keyword">new</span> <span class="type">ExternalSorter</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">V</span>](</span><br><span class="line">      context, aggregator = <span class="type">None</span>, <span class="type">Some</span>(dep.partitioner), ordering = <span class="type">None</span>, dep.serializer)</span><br><span class="line">  &#125;</span><br><span class="line">  sorter.insertAll(records)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Don&#x27;t bother including the time to open the merged output file in the shuffle write time,</span></span><br><span class="line">  <span class="comment">// because it just opens a single file, so is typically too fast to measure accurately</span></span><br><span class="line">  <span class="comment">// (see SPARK-3570).</span></span><br><span class="line">  <span class="keyword">val</span> output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId)</span><br><span class="line">  <span class="keyword">val</span> tmp = <span class="type">Utils</span>.tempFileWith(output)</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> blockId = <span class="type">ShuffleBlockId</span>(dep.shuffleId, mapId, <span class="type">IndexShuffleBlockResolver</span>.<span class="type">NOOP_REDUCE_ID</span>)</span><br><span class="line">    <span class="keyword">val</span> partitionLengths = sorter.writePartitionedFile(blockId, tmp)</span><br><span class="line">    <span class="comment">// 写入索引文件</span></span><br><span class="line">    shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp)</span><br><span class="line">    mapStatus = <span class="type">MapStatus</span>(blockManager.shuffleServerId, partitionLengths)</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (tmp.exists() &amp;&amp; !tmp.delete()) &#123;</span><br><span class="line">      logError(<span class="string">s&quot;Error while deleting temp file <span class="subst">$&#123;tmp.getAbsolutePath&#125;</span>&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="ExternalSorter"><a href="#ExternalSorter" class="headerlink" title="ExternalSorter"></a>ExternalSorter</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对于需要聚合的，使用该map；</span></span><br><span class="line"><span class="comment">// 对于不需要聚合的，使用该buffer，注意，这里的C与原始记录的V类型是一致的</span></span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> map = <span class="keyword">new</span> <span class="type">PartitionedAppendOnlyMap</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> buffer = <span class="keyword">new</span> <span class="type">PartitionedPairBuffer</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> spills = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">SpilledFile</span>]</span><br><span class="line"><span class="comment">// 溢出数据总量</span></span><br><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> _memoryBytesSpilled = <span class="number">0</span>L</span><br><span class="line"></span><br><span class="line"><span class="comment">// 溢出次数</span></span><br><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> _spillCount = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 分区内部，对于记录按key进行排序，规则为：</span></span><br><span class="line"><span class="comment">// 1.如果定义了ordering，使用定义的排序规则；</span></span><br><span class="line"><span class="comment">// 2.否则，使用基于记录中key的hash值进行排序；</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> keyComparator: <span class="type">Comparator</span>[<span class="type">K</span>] = ordering.getOrElse(<span class="keyword">new</span> <span class="type">Comparator</span>[<span class="type">K</span>] &#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: <span class="type">K</span>, b: <span class="type">K</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> h1 = <span class="keyword">if</span> (a == <span class="literal">null</span>) <span class="number">0</span> <span class="keyword">else</span> a.hashCode()</span><br><span class="line">    <span class="keyword">val</span> h2 = <span class="keyword">if</span> (b == <span class="literal">null</span>) <span class="number">0</span> <span class="keyword">else</span> b.hashCode()</span><br><span class="line">    <span class="keyword">if</span> (h1 &lt; h2) <span class="number">-1</span> <span class="keyword">else</span> <span class="keyword">if</span> (h1 == h2) <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">comparator</span></span>: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]] = &#123;</span><br><span class="line">  <span class="keyword">if</span> (ordering.isDefined || aggregator.isDefined) &#123;</span><br><span class="line">    <span class="type">Some</span>(keyComparator)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="写入数据-1"><a href="#写入数据-1" class="headerlink" title="写入数据"></a>写入数据</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertAll</span></span>(records: <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> stop combining if we find that the reduction factor isn&#x27;t high</span></span><br><span class="line">  <span class="keyword">val</span> shouldCombine = aggregator.isDefined</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (shouldCombine) &#123;</span><br><span class="line">    <span class="comment">// Combine values in-memory first using our AppendOnlyMap</span></span><br><span class="line">    <span class="keyword">val</span> mergeValue = aggregator.get.mergeValue</span><br><span class="line">    <span class="keyword">val</span> createCombiner = aggregator.get.createCombiner</span><br><span class="line">    <span class="keyword">var</span> kv: <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>] = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">val</span> update = (hadValue: <span class="type">Boolean</span>, oldValue: <span class="type">C</span>) =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (hadValue) mergeValue(oldValue, kv._2) <span class="keyword">else</span> createCombiner(kv._2)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (records.hasNext) &#123;</span><br><span class="line">      addElementsRead()</span><br><span class="line">      kv = records.next()</span><br><span class="line">      map.changeValue((getPartition(kv._1), kv._1), update) <span class="comment">// map更新插入</span></span><br><span class="line">      maybeSpillCollection(usingMap = <span class="literal">true</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Stick values into our buffer</span></span><br><span class="line">    <span class="keyword">while</span> (records.hasNext) &#123;</span><br><span class="line">      addElementsRead()</span><br><span class="line">      <span class="keyword">val</span> kv = records.next()</span><br><span class="line">      buffer.insert(getPartition(kv._1), kv._1, kv._2.asInstanceOf[<span class="type">C</span>])<span class="comment">// buffer插入</span></span><br><span class="line">      maybeSpillCollection(usingMap = <span class="literal">false</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="溢出-1"><a href="#溢出-1" class="headerlink" title="溢出"></a>溢出</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeSpillCollection</span></span>(usingMap: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> estimatedSize = <span class="number">0</span>L</span><br><span class="line">  <span class="keyword">if</span> (usingMap) &#123;</span><br><span class="line">    <span class="comment">// 评估当前内存集合的数据量大小</span></span><br><span class="line">    estimatedSize = map.estimateSize()</span><br><span class="line">    <span class="keyword">if</span> (maybeSpill(map, estimatedSize)) &#123;</span><br><span class="line">      map = <span class="keyword">new</span> <span class="type">PartitionedAppendOnlyMap</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 评估当前内存集合的数据量大小</span></span><br><span class="line">    estimatedSize = buffer.estimateSize()</span><br><span class="line">    <span class="keyword">if</span> (maybeSpill(buffer, estimatedSize)) &#123;</span><br><span class="line">      buffer = <span class="keyword">new</span> <span class="type">PartitionedPairBuffer</span>[<span class="type">K</span>, <span class="type">C</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (estimatedSize &gt; _peakMemoryUsedBytes) &#123;</span><br><span class="line">    _peakMemoryUsedBytes = estimatedSize</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Spills the current in-memory collection to disk if needed. Attempts to acquire more</span></span><br><span class="line"><span class="comment"> * memory before spilling.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param collection collection to spill to disk</span></span><br><span class="line"><span class="comment"> * @param currentMemory estimated size of the collection in bytes</span></span><br><span class="line"><span class="comment"> * @return true if `collection` was spilled to disk; false otherwise</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">maybeSpill</span></span>(collection: <span class="type">C</span>, currentMemory: <span class="type">Long</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">  <span class="keyword">var</span> shouldSpill = <span class="literal">false</span></span><br><span class="line">  <span class="comment">// 当前内存集合记录数是否为32的倍数，即，每添加32个record到内存集合判断一次是否是需要进行溢出</span></span><br><span class="line">  <span class="keyword">if</span> (elementsRead % <span class="number">32</span> == <span class="number">0</span> &amp;&amp; currentMemory &gt;= myMemoryThreshold) &#123;</span><br><span class="line">    <span class="comment">// 从执行内存中申请2倍于当前内存集合的空间</span></span><br><span class="line">    <span class="keyword">val</span> amountToRequest = <span class="number">2</span> * currentMemory - myMemoryThreshold</span><br><span class="line">    <span class="keyword">val</span> granted = acquireMemory(amountToRequest)</span><br><span class="line">    myMemoryThreshold += granted</span><br><span class="line">    <span class="comment">// 如果没有申请到足够的内存，则将当前的集合溢出到磁盘</span></span><br><span class="line">    shouldSpill = currentMemory &gt;= myMemoryThreshold</span><br><span class="line">  &#125;</span><br><span class="line">  shouldSpill = shouldSpill || _elementsRead &gt; numElementsForceSpillThreshold</span><br><span class="line">  <span class="comment">// Actually spill</span></span><br><span class="line">  <span class="keyword">if</span> (shouldSpill) &#123;</span><br><span class="line">    _spillCount += <span class="number">1</span></span><br><span class="line">    logSpillage(currentMemory)</span><br><span class="line">    spill(collection)</span><br><span class="line">    _elementsRead = <span class="number">0</span></span><br><span class="line">    _memoryBytesSpilled += currentMemory</span><br><span class="line">    releaseMemory()</span><br><span class="line">  &#125;</span><br><span class="line">  shouldSpill</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将内存集合溢出到排序文件中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">override</span> <span class="keyword">protected</span>[<span class="keyword">this</span>] <span class="function"><span class="keyword">def</span> <span class="title">spill</span></span>(collection: <span class="type">WritablePartitionedPairCollection</span>[<span class="type">K</span>, <span class="type">C</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> inMemoryIterator = collection.destructiveSortedWritablePartitionedIterator(comparator)</span><br><span class="line">  <span class="keyword">val</span> spillFile = spillMemoryIteratorToDisk(inMemoryIterator)</span><br><span class="line">  spills += spillFile</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] <span class="function"><span class="keyword">def</span> <span class="title">spillMemoryIteratorToDisk</span></span>(inMemoryIterator: <span class="type">WritablePartitionedIterator</span>)</span><br><span class="line">    : <span class="type">SpilledFile</span> = &#123;</span><br><span class="line">  <span class="comment">// Because these files may be read during shuffle, their compression must be controlled by</span></span><br><span class="line">  <span class="comment">// spark.shuffle.compress instead of spark.shuffle.spill.compress, so we need to use</span></span><br><span class="line">  <span class="comment">// createTempShuffleBlock here; see SPARK-3426 for more context.</span></span><br><span class="line">  <span class="keyword">val</span> (blockId, file) = diskBlockManager.createTempShuffleBlock()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// These variables are reset after each flush</span></span><br><span class="line">  <span class="keyword">var</span> objectsWritten: <span class="type">Long</span> = <span class="number">0</span></span><br><span class="line">  <span class="keyword">val</span> spillMetrics: <span class="type">ShuffleWriteMetrics</span> = <span class="keyword">new</span> <span class="type">ShuffleWriteMetrics</span></span><br><span class="line">  <span class="keyword">val</span> writer: <span class="type">DiskBlockObjectWriter</span> =</span><br><span class="line">    blockManager.getDiskWriter(blockId, file, serInstance, fileBufferSize, spillMetrics)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// List of batch sizes (bytes) in the order they are written to disk</span></span><br><span class="line">  <span class="keyword">val</span> batchSizes = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Long</span>]</span><br><span class="line"></span><br><span class="line">  <span class="comment">// How many elements we have in each partition</span></span><br><span class="line">  <span class="keyword">val</span> elementsPerPartition = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Long</span>](numPartitions)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Flush the disk writer&#x27;s contents to disk, and update relevant variables.</span></span><br><span class="line">  <span class="comment">// The writer is committed at the end of this process.</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">flush</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> segment = writer.commitAndGet()</span><br><span class="line">    batchSizes += segment.length</span><br><span class="line">    _diskBytesSpilled += segment.length</span><br><span class="line">    objectsWritten = <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> success = <span class="literal">false</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (inMemoryIterator.hasNext) &#123;</span><br><span class="line">      <span class="keyword">val</span> partitionId = inMemoryIterator.nextPartition()</span><br><span class="line">      require(partitionId &gt;= <span class="number">0</span> &amp;&amp; partitionId &lt; numPartitions,</span><br><span class="line">        <span class="string">s&quot;partition Id: <span class="subst">$&#123;partitionId&#125;</span> should be in the range [0, <span class="subst">$&#123;numPartitions&#125;</span>)&quot;</span>)</span><br><span class="line">      inMemoryIterator.writeNext(writer)</span><br><span class="line">      elementsPerPartition(partitionId) += <span class="number">1</span></span><br><span class="line">      objectsWritten += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (objectsWritten == serializerBatchSize) &#123;</span><br><span class="line">        flush()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (objectsWritten &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      flush()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      writer.revertPartialWritesAndClose()</span><br><span class="line">    &#125;</span><br><span class="line">    success = <span class="literal">true</span></span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (success) &#123;</span><br><span class="line">      writer.close()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// This code path only happens if an exception was thrown above before we set success;</span></span><br><span class="line">      <span class="comment">// close our stuff and let the exception be thrown further</span></span><br><span class="line">      writer.revertPartialWritesAndClose()</span><br><span class="line">      <span class="keyword">if</span> (file.exists()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!file.delete()) &#123;</span><br><span class="line">          logWarning(<span class="string">s&quot;Error deleting <span class="subst">$&#123;file&#125;</span>&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">SpilledFile</span>(file, blockId, batchSizes.toArray, elementsPerPartition)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="合并文件-1"><a href="#合并文件-1" class="headerlink" title="合并文件"></a>合并文件</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">writePartitionedFile</span></span>(</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    outputFile: <span class="type">File</span>): <span class="type">Array</span>[<span class="type">Long</span>] = &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Track location of each range in the output file</span></span><br><span class="line">  <span class="keyword">val</span> lengths = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Long</span>](numPartitions)</span><br><span class="line">  <span class="keyword">val</span> writer = blockManager.getDiskWriter(blockId, outputFile, serInstance, fileBufferSize,</span><br><span class="line">    context.taskMetrics().shuffleWriteMetrics)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (spills.isEmpty) &#123;<span class="comment">// 只有内存数据，没有溢出数据</span></span><br><span class="line">    <span class="comment">// Case where we only have in-memory data</span></span><br><span class="line">    <span class="keyword">val</span> collection = <span class="keyword">if</span> (aggregator.isDefined) map <span class="keyword">else</span> buffer</span><br><span class="line">    <span class="keyword">val</span> it = collection.destructiveSortedWritablePartitionedIterator(comparator)</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext) &#123;</span><br><span class="line">      <span class="keyword">val</span> partitionId = it.nextPartition()</span><br><span class="line">      <span class="keyword">while</span> (it.hasNext &amp;&amp; it.nextPartition() == partitionId) &#123;</span><br><span class="line">        it.writeNext(writer)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> segment = writer.commitAndGet()</span><br><span class="line">      lengths(partitionId) = segment.length</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;<span class="comment">// 有溢出数据，需要进行溢出数据和内存中的数据进行归并排序</span></span><br><span class="line">    <span class="comment">// We must perform merge-sort; get an iterator by partition and write everything directly.</span></span><br><span class="line">    <span class="keyword">for</span> ((id, elements) &lt;- <span class="keyword">this</span>.partitionedIterator) &#123;</span><br><span class="line">      <span class="keyword">if</span> (elements.hasNext) &#123;</span><br><span class="line">        <span class="keyword">for</span> (elem &lt;- elements) &#123; <span class="comment">// 将一个分区中的数据按序写入到文件流</span></span><br><span class="line">          writer.write(elem._1, elem._2)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">val</span> segment = writer.commitAndGet() <span class="comment">// 每个分区进行一次提交</span></span><br><span class="line">        lengths(id) = segment.length</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  writer.close()</span><br><span class="line">  context.taskMetrics().incMemoryBytesSpilled(memoryBytesSpilled)</span><br><span class="line">  context.taskMetrics().incDiskBytesSpilled(diskBytesSpilled)</span><br><span class="line">  context.taskMetrics().incPeakExecutionMemory(peakMemoryUsedBytes)</span><br><span class="line"></span><br><span class="line">  lengths</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return an iterator over all the data written to this object, grouped by partition and</span></span><br><span class="line"><span class="comment"> * aggregated by the requested aggregator. For each partition we then have an iterator over its</span></span><br><span class="line"><span class="comment"> * contents, and these are expected to be accessed in order (you can&#x27;t &quot;skip ahead&quot; to one</span></span><br><span class="line"><span class="comment"> * partition without reading the previous one). Guaranteed to return a key-value pair for each</span></span><br><span class="line"><span class="comment"> * partition, in order of partition ID.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * For now, we just merge all the spilled files in once pass, but this can be modified to</span></span><br><span class="line"><span class="comment"> * support hierarchical merging.</span></span><br><span class="line"><span class="comment"> * Exposed for testing.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionedIterator</span></span>: <span class="type">Iterator</span>[(<span class="type">Int</span>, <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]])] = &#123;</span><br><span class="line">  <span class="keyword">val</span> usingMap = aggregator.isDefined</span><br><span class="line">  <span class="keyword">val</span> collection: <span class="type">WritablePartitionedPairCollection</span>[<span class="type">K</span>, <span class="type">C</span>] = <span class="keyword">if</span> (usingMap) map <span class="keyword">else</span> buffer</span><br><span class="line">  <span class="keyword">if</span> (spills.isEmpty) &#123;</span><br><span class="line">    <span class="comment">// Special case: if we have only in-memory data, we don&#x27;t need to merge streams, and perhaps</span></span><br><span class="line">    <span class="comment">// we don&#x27;t even need to sort by anything other than partition ID</span></span><br><span class="line">    <span class="keyword">if</span> (!ordering.isDefined) &#123;</span><br><span class="line">      <span class="comment">// The user hasn&#x27;t requested sorted keys, so only sort by partition ID, not key</span></span><br><span class="line">      groupByPartition(destructiveIterator(collection.partitionedDestructiveSortedIterator(<span class="type">None</span>)))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// We do need to sort by both partition ID and key</span></span><br><span class="line">      groupByPartition(destructiveIterator(</span><br><span class="line">        collection.partitionedDestructiveSortedIterator(<span class="type">Some</span>(keyComparator))))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Merge spilled and in-memory data</span></span><br><span class="line">    merge(spills, destructiveIterator(</span><br><span class="line">      collection.partitionedDestructiveSortedIterator(comparator)))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回一个破环性的迭代器来遍历该map中的记录。</span></span><br><span class="line"><span class="comment"> * 如果在没有足够内存时，该迭代器会被迫溢出到磁盘来释放内存，从而它返回的是来自基于磁盘map的KV对。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">destructiveIterator</span></span>(memoryIterator: <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>)]): <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>)] = &#123;</span><br><span class="line">  <span class="keyword">if</span> (isShuffleSort) &#123;</span><br><span class="line">    memoryIterator</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    readingIterator = <span class="keyword">new</span> <span class="type">SpillableIterator</span>(memoryIterator)</span><br><span class="line">    readingIterator</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将所有溢出的文件和内存中的数据进行合并，返回一个迭代器，该迭代器的数据项为：(分区ID，分区内记录迭代器)</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">merge</span></span>(spills: <span class="type">Seq</span>[<span class="type">SpilledFile</span>], inMemory: <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>)])</span><br><span class="line">    : <span class="type">Iterator</span>[(<span class="type">Int</span>, <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]])] = &#123;</span><br><span class="line">  <span class="comment">// 每个溢出文件创建一个SpillReader</span></span><br><span class="line">  <span class="keyword">val</span> readers = spills.map(<span class="keyword">new</span> <span class="type">SpillReader</span>(_))</span><br><span class="line">  <span class="keyword">val</span> inMemBuffered = inMemory.buffered</span><br><span class="line">  (<span class="number">0</span> until numPartitions).iterator.map &#123; p =&gt;</span><br><span class="line">    <span class="comment">// 包装为IteratorForPartition</span></span><br><span class="line">    <span class="keyword">val</span> inMemIterator = <span class="keyword">new</span> <span class="type">IteratorForPartition</span>(p, inMemBuffered)</span><br><span class="line">    <span class="comment">// 将溢出文件的分区迭代器和内存的分区迭代器合并</span></span><br><span class="line">    <span class="keyword">val</span> iterators = readers.map(_.readNextPartition()) ++ <span class="type">Seq</span>(inMemIterator)</span><br><span class="line">    <span class="keyword">if</span> (aggregator.isDefined) &#123; <span class="comment">// 如果需要聚合，对当前分区执行聚合</span></span><br><span class="line">      <span class="comment">// Perform partial aggregation across partitions</span></span><br><span class="line">      (p, mergeWithAggregation(</span><br><span class="line">        iterators, aggregator.get.mergeCombiners, keyComparator, ordering.isDefined))</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ordering.isDefined) &#123; <span class="comment">// 如果不需要聚合，但定义了排序，对当前分区执行归并排序</span></span><br><span class="line">      <span class="comment">// No aggregator given, but we have an ordering (e.g. used by reduce tasks in sortByKey);</span></span><br><span class="line">      <span class="comment">// sort the elements without trying to merge them</span></span><br><span class="line">      (p, mergeSort(iterators, ordering.get))</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// 否则，直接对各迭代器进行合并作为当前分区的数据</span></span><br><span class="line">      (p, iterators.iterator.flatten)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Merge-sort a sequence of (K, C) iterators using a given a comparator for the keys.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span></span>(iterators: <span class="type">Seq</span>[<span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]]], comparator: <span class="type">Comparator</span>[<span class="type">K</span>])</span><br><span class="line">    : <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] =</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">val</span> bufferedIters = iterators.filter(_.hasNext).map(_.buffered)</span><br><span class="line">  <span class="class"><span class="keyword">type</span> <span class="title">Iter</span> </span>= <span class="type">BufferedIterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]]</span><br><span class="line">  <span class="keyword">val</span> heap = <span class="keyword">new</span> mutable.<span class="type">PriorityQueue</span>[<span class="type">Iter</span>]()(<span class="keyword">new</span> <span class="type">Ordering</span>[<span class="type">Iter</span>] &#123;</span><br><span class="line">    <span class="comment">// 对元素的key进行排序，注意这里对key进行了升序的处理</span></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(x: <span class="type">Iter</span>, y: <span class="type">Iter</span>): <span class="type">Int</span> = comparator.compare(y.head._1, x.head._1) </span><br><span class="line">  &#125;)</span><br><span class="line">  heap.enqueue(bufferedIters: _*)  <span class="comment">// Will contain only the iterators with hasNext = true</span></span><br><span class="line">  <span class="keyword">new</span> <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = !heap.isEmpty</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>] = &#123;</span><br><span class="line">      <span class="keyword">if</span> (!hasNext) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoSuchElementException</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> firstBuf = heap.dequeue() <span class="comment">// key最小的记录所在的迭代器出队</span></span><br><span class="line">      <span class="keyword">val</span> firstPair = firstBuf.next() <span class="comment">// 因为使用的是BufferedIterator，next()返回head的值，并不向后推进迭代器</span></span><br><span class="line">      <span class="keyword">if</span> (firstBuf.hasNext) &#123; <span class="comment">// 如果出队的迭代器还有记录，将其入队</span></span><br><span class="line">        heap.enqueue(firstBuf)</span><br><span class="line">      &#125;</span><br><span class="line">      firstPair</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>归并排序图示：</p>
<p><img src="/images/spark/ExternalSorter-mergeSort.svg"></p>
<br/>

<h2 id="SpillableIterator"><a href="#SpillableIterator" class="headerlink" title="SpillableIterator"></a>SpillableIterator</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] <span class="class"><span class="keyword">class</span> <span class="title">SpillableIterator</span>(<span class="params">var upstream: <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span></span>), <span class="title">C</span>)])</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>)] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> <span class="type">SPILL_LOCK</span> = <span class="keyword">new</span> <span class="type">Object</span>()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> nextUpstream: <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>)] = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> cur: ((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>) = readNext()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> hasSpilled: <span class="type">Boolean</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">spill</span></span>(): <span class="type">Boolean</span> = <span class="type">SPILL_LOCK</span>.synchronized &#123;</span><br><span class="line">    <span class="keyword">if</span> (hasSpilled) &#123;</span><br><span class="line">      <span class="literal">false</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> inMemoryIterator = <span class="keyword">new</span> <span class="type">WritablePartitionedIterator</span> &#123;</span><br><span class="line">        <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> cur = <span class="keyword">if</span> (upstream.hasNext) upstream.next() <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">writeNext</span></span>(writer: <span class="type">DiskBlockObjectWriter</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">          writer.write(cur._1._2, cur._2)</span><br><span class="line">          cur = <span class="keyword">if</span> (upstream.hasNext) upstream.next() <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>(): <span class="type">Boolean</span> = cur != <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">nextPartition</span></span>(): <span class="type">Int</span> = cur._1._1</span><br><span class="line">      &#125;</span><br><span class="line">      logInfo(<span class="string">s&quot;Task <span class="subst">$&#123;context.taskAttemptId&#125;</span> force spilling in-memory map to disk and &quot;</span> +</span><br><span class="line">        <span class="string">s&quot; it will release <span class="subst">$&#123;org.apache.spark.util.Utils.bytesToString(getUsed())&#125;</span> memory&quot;</span>)</span><br><span class="line">      <span class="keyword">val</span> spillFile = spillMemoryIteratorToDisk(inMemoryIterator)</span><br><span class="line">      forceSpillFiles += spillFile</span><br><span class="line">      <span class="keyword">val</span> spillReader = <span class="keyword">new</span> <span class="type">SpillReader</span>(spillFile)</span><br><span class="line">      nextUpstream = (<span class="number">0</span> until numPartitions).iterator.flatMap &#123; p =&gt;</span><br><span class="line">        <span class="keyword">val</span> iterator = spillReader.readNextPartition()</span><br><span class="line">        iterator.map(cur =&gt; ((p, cur._1), cur._2))</span><br><span class="line">      &#125;</span><br><span class="line">      hasSpilled = <span class="literal">true</span></span><br><span class="line">      <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">readNext</span></span>(): ((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>) = <span class="type">SPILL_LOCK</span>.synchronized &#123;</span><br><span class="line">    <span class="keyword">if</span> (nextUpstream != <span class="literal">null</span>) &#123;</span><br><span class="line">      upstream = nextUpstream</span><br><span class="line">      nextUpstream = <span class="literal">null</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (upstream.hasNext) &#123;</span><br><span class="line">      upstream.next()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="literal">null</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>(): <span class="type">Boolean</span> = cur != <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): ((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">C</span>) = &#123;</span><br><span class="line">    <span class="keyword">val</span> r = cur</span><br><span class="line">    cur = readNext()</span><br><span class="line">    r</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="SpillReader"><a href="#SpillReader" class="headerlink" title="SpillReader"></a>SpillReader</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Construct a stream that only reads from the next batch */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nextBatchStream</span></span>(): <span class="type">DeserializationStream</span> = &#123;</span><br><span class="line">  <span class="comment">// Note that batchOffsets.length = numBatches + 1 since we did a scan above; check whether</span></span><br><span class="line">  <span class="comment">// we&#x27;re still in a valid batch.</span></span><br><span class="line">  <span class="keyword">if</span> (batchId &lt; batchOffsets.length - <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (deserializeStream != <span class="literal">null</span>) &#123;</span><br><span class="line">      deserializeStream.close()</span><br><span class="line">      fileStream.close()</span><br><span class="line">      deserializeStream = <span class="literal">null</span></span><br><span class="line">      fileStream = <span class="literal">null</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> start = batchOffsets(batchId) <span class="comment">// 每个batch的起始字节</span></span><br><span class="line">    fileStream = <span class="keyword">new</span> <span class="type">FileInputStream</span>(spill.file)</span><br><span class="line">    fileStream.getChannel.position(start)</span><br><span class="line">    batchId += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> end = batchOffsets(batchId) <span class="comment">// 每个batch的结束字节</span></span><br><span class="line"></span><br><span class="line">    assert(end &gt;= start, <span class="string">&quot;start = &quot;</span> + start + <span class="string">&quot;, end = &quot;</span> + end +</span><br><span class="line">      <span class="string">&quot;, batchOffsets = &quot;</span> + batchOffsets.mkString(<span class="string">&quot;[&quot;</span>, <span class="string">&quot;, &quot;</span>, <span class="string">&quot;]&quot;</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 从文件流中读取(end - start)个字节</span></span><br><span class="line">    <span class="keyword">val</span> bufferedStream = <span class="keyword">new</span> <span class="type">BufferedInputStream</span>(<span class="type">ByteStreams</span>.limit(fileStream, end - start))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> wrappedStream = serializerManager.wrapStream(spill.blockId, bufferedStream)</span><br><span class="line">    <span class="comment">// 返回当前batch数据的解序列化流</span></span><br><span class="line">    serInstance.deserializeStream(wrappedStream)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// No more batches left</span></span><br><span class="line">    cleanup()</span><br><span class="line">    <span class="literal">null</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readNextPartition</span></span>(): <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] = <span class="keyword">new</span> <span class="type">Iterator</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>]] &#123; <span class="comment">// 创建该分区的迭代器</span></span><br><span class="line">  <span class="keyword">val</span> myPartition = nextPartitionToRead</span><br><span class="line">  nextPartitionToRead += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// ExternalSorter.mergeSort()每次出队时，会先调用next()，拿到缓存的nextItem，</span></span><br><span class="line">  <span class="comment">// 然后调用hasNext()读取下一个元素，并设置给nextItem</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (nextItem == <span class="literal">null</span>) &#123;</span><br><span class="line">      nextItem = readNextItem()</span><br><span class="line">      <span class="keyword">if</span> (nextItem == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    assert(lastPartitionId &gt;= myPartition)</span><br><span class="line">    <span class="comment">// Check that we&#x27;re still in the right partition; note that readNextItem will have returned</span></span><br><span class="line">    <span class="comment">// null at EOF above so we would&#x27;ve returned false there</span></span><br><span class="line">    lastPartitionId == myPartition</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ExternalSorter.mergeSort()每次出队时，会调用此方法进行判断</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">C</span>] = &#123;</span><br><span class="line">    <span class="keyword">if</span> (!hasNext) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoSuchElementException</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">val</span> item = nextItem <span class="comment">// 直接返回nextItem作为下一个元素</span></span><br><span class="line">    nextItem = <span class="literal">null</span> <span class="comment">// 置空，这样当调用hasNext()时就会触发readNextItem()读取下一个元素</span></span><br><span class="line">    item</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从解序列化流中读取下一个(K,C)对，如果当前batch被消费完了，那么触发下一个batch的读取</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">readNextItem</span></span>(): (<span class="type">K</span>, <span class="type">C</span>) = &#123;</span><br><span class="line">  <span class="keyword">if</span> (finished || deserializeStream == <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">val</span> k = deserializeStream.readKey().asInstanceOf[<span class="type">K</span>]</span><br><span class="line">  <span class="keyword">val</span> c = deserializeStream.readValue().asInstanceOf[<span class="type">C</span>]</span><br><span class="line">  lastPartitionId = partitionId</span><br><span class="line">  <span class="comment">// Start reading the next batch if we&#x27;re done with this one</span></span><br><span class="line">  indexInBatch += <span class="number">1</span></span><br><span class="line">  <span class="keyword">if</span> (indexInBatch == serializerBatchSize) &#123;</span><br><span class="line">    indexInBatch = <span class="number">0</span></span><br><span class="line">    deserializeStream = nextBatchStream()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Update the partition location of the element we&#x27;re reading</span></span><br><span class="line">  indexInPartition += <span class="number">1</span></span><br><span class="line">  skipToNextPartition()</span><br><span class="line">  <span class="comment">// If we&#x27;ve finished reading the last partition, remember that we&#x27;re done</span></span><br><span class="line">  <span class="keyword">if</span> (partitionId == numPartitions) &#123;</span><br><span class="line">    finished = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">if</span> (deserializeStream != <span class="literal">null</span>) &#123;</span><br><span class="line">      deserializeStream.close()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  (k, c)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="WritablePartitionedPairCollection"><a href="#WritablePartitionedPairCollection" class="headerlink" title="WritablePartitionedPairCollection"></a>WritablePartitionedPairCollection</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> Iterate through the data and write out the elements instead of returning them. Records are</span></span><br><span class="line"><span class="comment"> * returned in order of their partition ID and then the given comparator.</span></span><br><span class="line"><span class="comment"> * This may destroy the underlying collection.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 其中的keyComparator为ExternalSorter中的定义的</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">destructiveSortedWritablePartitionedIterator</span></span>(keyComparator: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]])</span><br><span class="line">  : <span class="type">WritablePartitionedIterator</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> it = partitionedDestructiveSortedIterator(keyComparator)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">WritablePartitionedIterator</span> &#123;</span><br><span class="line">    <span class="keyword">private</span>[<span class="keyword">this</span>] <span class="keyword">var</span> cur = <span class="keyword">if</span> (it.hasNext) it.next() <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">writeNext</span></span>(writer: <span class="type">DiskBlockObjectWriter</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">      writer.write(cur._1._2, cur._2)</span><br><span class="line">      cur = <span class="keyword">if</span> (it.hasNext) it.next() <span class="keyword">else</span> <span class="literal">null</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>(): <span class="type">Boolean</span> = cur != <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nextPartition</span></span>(): <span class="type">Int</span> = cur._1._1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="工具方法"><a href="#工具方法" class="headerlink" title="工具方法"></a>工具方法</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">object</span> <span class="title">WritablePartitionedPairCollection</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A comparator for (Int, K) pairs that orders them by only their partition ID.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">partitionComparator</span></span>[<span class="type">K</span>]: <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] = <span class="keyword">new</span> <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] &#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: (<span class="type">Int</span>, <span class="type">K</span>), b: (<span class="type">Int</span>, <span class="type">K</span>)): <span class="type">Int</span> = &#123;</span><br><span class="line">      a._1 - b._1</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A comparator for (Int, K) pairs that orders them both by their partition ID and a key ordering.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">partitionKeyComparator</span></span>[<span class="type">K</span>](keyComparator: <span class="type">Comparator</span>[<span class="type">K</span>]): <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">Comparator</span>[(<span class="type">Int</span>, <span class="type">K</span>)] &#123;</span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: (<span class="type">Int</span>, <span class="type">K</span>), b: (<span class="type">Int</span>, <span class="type">K</span>)): <span class="type">Int</span> = &#123;</span><br><span class="line">        <span class="keyword">val</span> partitionDiff = a._1 - b._1</span><br><span class="line">        <span class="keyword">if</span> (partitionDiff != <span class="number">0</span>) &#123; <span class="comment">// 对内存集合中记录排序时，首先比较其分区，分区ID作为第一排序依据</span></span><br><span class="line">          partitionDiff</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          keyComparator.compare(a._2, b._2) <span class="comment">// 分区相同，分区内部中记录按“键”进行排序</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="PartitionedAppendOnlyMap"><a href="#PartitionedAppendOnlyMap" class="headerlink" title="PartitionedAppendOnlyMap"></a>PartitionedAppendOnlyMap</h2><p>该类继承自<code>SizeTrackingAppendOnlyMap[(Int, K), V]</code>，(Int, K)为底层map的键类型（其中int为记录的分区ID），V为底层map的值类型。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">PartitionedAppendOnlyMap</span>[<span class="type">K</span>, <span class="type">V</span>]</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">SizeTrackingAppendOnlyMap</span>[(<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>] <span class="keyword">with</span> <span class="title">WritablePartitionedPairCollection</span>[<span class="type">K</span>, <span class="type">V</span>] </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">partitionedDestructiveSortedIterator</span></span>(keyComparator: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]])</span><br><span class="line">    : <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>)] = &#123;</span><br><span class="line">    <span class="comment">// 对内存集合中记录排序时，首先比较其分区，分区ID作为第一排序依据，分区相同，分区内部中记录按“键”进行排序；</span></span><br><span class="line">    <span class="comment">// 如果不需要shuffle操作是不排序/不聚合的操作，那么只按照分区ID进行排序；</span></span><br><span class="line">    <span class="keyword">val</span> comparator = keyComparator.map(partitionKeyComparator).getOrElse(partitionComparator)</span><br><span class="line">    destructiveSortedIterator(comparator)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">insert</span></span>(partition: <span class="type">Int</span>, key: <span class="type">K</span>, value: <span class="type">V</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    update((partition, key), value)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<br/>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回该map结构的排序的迭代器。实现原理是破坏底层为了支持map存储的数组的数据结构，将将底层数据中的KV数据移到数组前部，</span></span><br><span class="line"><span class="comment"> * 然后，对重排后的数组进行排序</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">destructiveSortedIterator</span></span>(keyComparator: <span class="type">Comparator</span>[<span class="type">K</span>]): <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">V</span>)] = &#123;</span><br><span class="line">  destroyed = <span class="literal">true</span></span><br><span class="line">  <span class="comment">// 将底层数据中的KV数据移到数组前部，这样就破坏了底层数据对于map的支持，所以该方法的名称为“破坏性排序的迭代器”</span></span><br><span class="line">  <span class="keyword">var</span> keyIndex, newIndex = <span class="number">0</span></span><br><span class="line">  <span class="keyword">while</span> (keyIndex &lt; capacity) &#123;</span><br><span class="line">    <span class="keyword">if</span> (data(<span class="number">2</span> * keyIndex) != <span class="literal">null</span>) &#123;</span><br><span class="line">      data(<span class="number">2</span> * newIndex) = data(<span class="number">2</span> * keyIndex)</span><br><span class="line">      data(<span class="number">2</span> * newIndex + <span class="number">1</span>) = data(<span class="number">2</span> * keyIndex + <span class="number">1</span>)</span><br><span class="line">      newIndex += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    keyIndex += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  assert(curSize == newIndex + (<span class="keyword">if</span> (haveNullValue) <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 内部使用TimSort排序</span></span><br><span class="line">  <span class="keyword">new</span> <span class="type">Sorter</span>(<span class="keyword">new</span> <span class="type">KVArraySortDataFormat</span>[<span class="type">K</span>, <span class="type">AnyRef</span>]).sort(data, <span class="number">0</span>, newIndex, keyComparator)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">new</span> <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">V</span>)] &#123;</span><br><span class="line">    <span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">var</span> nullValueReady = haveNullValue</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = (i &lt; newIndex || nullValueReady)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): (<span class="type">K</span>, <span class="type">V</span>) = &#123;</span><br><span class="line">      <span class="keyword">if</span> (nullValueReady) &#123;</span><br><span class="line">        nullValueReady = <span class="literal">false</span></span><br><span class="line">        (<span class="literal">null</span>.asInstanceOf[<span class="type">K</span>], nullValue)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> item = (data(<span class="number">2</span> * i).asInstanceOf[<span class="type">K</span>], data(<span class="number">2</span> * i + <span class="number">1</span>).asInstanceOf[<span class="type">V</span>])</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        item</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们来举例看一下这里的“破坏”底层数据前后对照：将有效数据移动到数组的前部</p>
<p><img src="/images/spark/AppendOnlyMap-destructiveSortedIterator.svg"></p>
<h2 id="PartitionedPairBuffer"><a href="#PartitionedPairBuffer" class="headerlink" title="PartitionedPairBuffer"></a>PartitionedPairBuffer</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">PartitionedPairBuffer</span>[<span class="type">K</span>, <span class="type">V</span>](<span class="params">initialCapacity: <span class="type">Int</span> = 64</span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">WritablePartitionedPairCollection</span>[<span class="type">K</span>, <span class="type">V</span>] <span class="keyword">with</span> <span class="title">SizeTracker</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> capacity = initialCapacity</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> curSize = <span class="number">0</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> data = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">AnyRef</span>](<span class="number">2</span> * initialCapacity)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Iterate through the data in a given order. For this class this is not really destructive. */</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">partitionedDestructiveSortedIterator</span></span>(keyComparator: <span class="type">Option</span>[<span class="type">Comparator</span>[<span class="type">K</span>]])</span><br><span class="line">    : <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>)] = &#123;</span><br><span class="line">    <span class="comment">// 对内存集合中记录排序时，首先比较其分区，分区ID作为第一排序依据，分区相同，分区内部中记录按“键”进行排序；</span></span><br><span class="line">    <span class="comment">// 如果不需要shuffle操作是不排序/不聚合的操作，那么只按照分区ID进行排序；</span></span><br><span class="line">    <span class="keyword">val</span> comparator = keyComparator.map(partitionKeyComparator).getOrElse(partitionComparator)</span><br><span class="line">    <span class="comment">// 内部使用TimSort排序</span></span><br><span class="line">    <span class="keyword">new</span> <span class="type">Sorter</span>(<span class="keyword">new</span> <span class="type">KVArraySortDataFormat</span>[(<span class="type">Int</span>, <span class="type">K</span>), <span class="type">AnyRef</span>]).sort(data, <span class="number">0</span>, curSize, comparator)</span><br><span class="line">    iterator</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">iterator</span></span>(): <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>)] = <span class="keyword">new</span> <span class="type">Iterator</span>[((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>)] &#123;</span><br><span class="line">    <span class="keyword">var</span> pos = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = pos &lt; curSize</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): ((<span class="type">Int</span>, <span class="type">K</span>), <span class="type">V</span>) = &#123;</span><br><span class="line">      <span class="keyword">if</span> (!hasNext) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">NoSuchElementException</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">val</span> pair = (data(<span class="number">2</span> * pos).asInstanceOf[(<span class="type">Int</span>, <span class="type">K</span>)], data(<span class="number">2</span> * pos + <span class="number">1</span>).asInstanceOf[<span class="type">V</span>])</span><br><span class="line">      pos += <span class="number">1</span></span><br><span class="line">      pair</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="NOTEs"><a href="#NOTEs" class="headerlink" title="NOTEs"></a>NOTEs</h1><p>本文以Spark 2.4.3为基础。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/08/05/Hexo-Usage/" rel="prev" title="Hexo 使用">
                  <i class="fa fa-chevron-left"></i> Hexo 使用
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/08/14/spark/Spark-rpc-details/" rel="next" title="Spark RPC原理">
                  Spark RPC原理 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JT Li</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"jtLiBrain","repo":"jtLiBrain.github.io","client_id":"c94aa78cf2eda71757bf","client_secret":"01e1353b3f8eac54aafb1224c784b7af0305ce8c","admin_user":"jtLiBrain","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"en","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"8b63e8956c2f57c05a13abb6363653a5"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
